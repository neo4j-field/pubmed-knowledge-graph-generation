{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PubMed Knowledge Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook walks through the process of generating a knowledge graph of PubMed articles.\n",
    "\n",
    "This notebook will\n",
    "* Download a selection of articles from PubMed\n",
    "* Define a knowledge graph schema\n",
    "* Extract entities from the articles according to the defined schema\n",
    "* Populate a Neo4j instance with articles and extracted entities\n",
    "* Connect extracted entities with existing patient journey data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook requires a local repo of articles. You may download a sample of 20 PubMed articles by running the following command.\n",
    "\n",
    "```bash\n",
    "python3 ./scripts/fetch_pubmed_articles.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Optional, List\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allows for async operations in notebooks\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lexical Graph Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Unstructured.IO to partition and chunk our articles. \n",
    "\n",
    "This process breaks the articles into sensible chunks that may be used as context in our application. \n",
    "\n",
    "These chunks will also have relationships to the extracted entities.\n",
    "\n",
    "IMAGE OF LEXICAL DATA MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from unstructured.partition.auto import partition\n",
    "from unstructured.documents.elements import CompositeElement\n",
    "\n",
    "from uuid import uuid4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Document(BaseModel):\n",
    "    id: str = Field(..., description=\"The id of the document\")\n",
    "    name: str = Field(..., description=\"The name of the document\")\n",
    "    source: str = Field(..., description=\"The source of the document\")\n",
    "\n",
    "class Chunk(BaseModel):\n",
    "    id: str = Field(..., description=\"The id of the chunk\")\n",
    "    text: str = Field(..., description=\"The text of the chunk\")\n",
    "\n",
    "class ChunkWithEmbedding(Chunk):\n",
    "    embedding: list[float] = Field(..., description=\"The embedding of the chunk text field\")\n",
    "\n",
    "class ChunkPartOfDocument(BaseModel):\n",
    "    chunk_id: str = Field(..., description=\"The id of the chunk\")\n",
    "    document_id: str = Field(..., description=\"The id of the document\")\n",
    "\n",
    "class ChunkHasEntity(BaseModel):\n",
    "    chunk_id: str = Field(..., description=\"The id of the chunk\")\n",
    "    entity_id: str = Field(..., description=\"The id of the entity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def element_to_node_and_relationship(element: CompositeElement, parent_document_id: str) -> dict[str, Chunk | ChunkPartOfDocument]:\n",
    "    \"\"\"Parse the entity node and document relationship for a given element\"\"\"\n",
    "    chunk = Chunk(id=element.id, text=element.text)\n",
    "    chunk_part_of_document = ChunkPartOfDocument(chunk_id=chunk.id, document_id=parent_document_id)\n",
    "    return {\n",
    "        \"nodes\": [chunk],\n",
    "        \"relationships\": [chunk_part_of_document],\n",
    "    }\n",
    "\n",
    "def elements_to_nodes_and_relationships(elements: list[CompositeElement], parent_document: Document) -> dict[str, list[Document | Chunk | ChunkPartOfDocument]]:\n",
    "    \"\"\"Parse entity nodes and document relationships for a set of elements and their parent document\"\"\"\n",
    "    \n",
    "    data = {\n",
    "        \"nodes\": [parent_document],\n",
    "        \"relationships\": list(),\n",
    "    }\n",
    "\n",
    "    for element in elements:\n",
    "        new_data = element_to_node_and_relationship(element, parent_document.id)\n",
    "        data[\"nodes\"].extend(new_data[\"nodes\"])\n",
    "        data[\"relationships\"].extend(new_data[\"relationships\"])\n",
    "\n",
    "    return data\n",
    "\n",
    "def process_article(file_name: str) -> dict[str, list[Document | Chunk | ChunkPartOfDocument]]:\n",
    "    parent_document = Document(id=str(uuid4()), name=file_name, source=\"pubmed\")\n",
    "    elements = partition(file_name, chunking_strategy=\"by_title\")\n",
    "    return elements_to_nodes_and_relationships(elements, parent_document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lexical Graph Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will embed the text fields of our lexical graph for vector similarity search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schema Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to define our knowledge graph schema. This information will be passed to the entity extraction LLM to control which entities and relationships are pulled out of the text.\n",
    "\n",
    "This is necessary to prevent our schema from growing too large with an unbounded extraction process.\n",
    "\n",
    "We are using Pydantic to define the schema here since it can be used to validate any returned results as well. This ensures that all data we are ingesting into Neo4j adheres to this structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Medication(BaseModel):\n",
    "    \"\"\"a substance used for medical treatment, especially a medicine or drug. This is a base medication, not a medication implemented in a study.\"\"\"\n",
    "    \n",
    "    medication_id: str = Field(..., description=\"Unique identifier for the medication\")\n",
    "    name: str = Field(..., description=\"Name of the medication. Should also be uniquely identifiable.\")\n",
    "    medication_class: str = Field(..., description=\"Drug class (e.g., GLP-1 RA, SGLT2i)\")\n",
    "    mechanism: Optional[str] = Field(None, description=\"Mechanism of action\")\n",
    "    generic_name: Optional[str] = Field(None, description=\"Generic name if different from name\")\n",
    "    brand_names: Optional[List[str]] = Field(None, description=\"Commercial brand names\")\n",
    "    approval_status: Optional[str] = Field(None, description=\"FDA approval status\")\n",
    "    \n",
    "    class Config:\n",
    "        json_schema_extra = {\n",
    "            \"examples\": [\n",
    "                {\n",
    "                    \"medication_id\": \"MED001\",\n",
    "                    \"name\": \"Semaglutide\", \n",
    "                    \"medication_class\": \"GLP-1 receptor agonist\",\n",
    "                    \"mechanism\": \"GLP-1 receptor activation\",\n",
    "                    \"generic_name\": \"semaglutide\",\n",
    "                    \"brand_names\": [\"Ozempic\", \"Wegovy\", \"Rybelsus\"],\n",
    "                    \"approval_status\": \"FDA approved\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "\n",
    "class StudyMedication(BaseModel):\n",
    "    \"\"\"Study-specific medication usage - how a medication was used in a particular study\"\"\"\n",
    "    \n",
    "    study_medication_id: str = Field(..., description=\"Unique identifier for this study medication instance\")\n",
    "    dosage: Optional[str] = Field(None, description=\"Dosage used in this study\")\n",
    "    route: Optional[str] = Field(None, description=\"Route of administration\")\n",
    "    frequency: Optional[str] = Field(None, description=\"Dosing frequency\")\n",
    "    treatment_duration: Optional[str] = Field(None, description=\"Duration of treatment\")\n",
    "    treatment_arm: Optional[str] = Field(None, description=\"Treatment arm description\")\n",
    "    comparator: Optional[str] = Field(None, description=\"What this was compared against\")\n",
    "    adherence_rate: Optional[float] = Field(None, description=\"Treatment adherence rate\")\n",
    "    formulation: Optional[str] = Field(None, description=\"Specific formulation used\")\n",
    "    \n",
    "    class Config:\n",
    "        json_schema_extra = {\n",
    "            \"examples\": [\n",
    "                {\n",
    "                    \"study_medication_id\": \"STUDY_MED001\",\n",
    "                    \"dosage\": \"1.0 mg\",\n",
    "                    \"route\": \"subcutaneous\",\n",
    "                    \"frequency\": \"weekly\",\n",
    "                    \"treatment_duration\": \"12 weeks\",\n",
    "                    \"treatment_arm\": \"Active treatment group\",\n",
    "                    \"comparator\": \"placebo\",\n",
    "                    \"adherence_rate\": 85.5,\n",
    "                    \"formulation\": \"pre-filled pen\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "\n",
    "class ClinicalOutcome(BaseModel):\n",
    "    \"\"\"Measured clinical outcomes and biomarkers\"\"\"\n",
    "    \n",
    "    clinical_outcome_id: str = Field(..., description=\"Unique identifier for the outcome\")\n",
    "    name: str = Field(..., description=\"Name of the clinical outcome\")\n",
    "    category: str = Field(..., description=\"Category of outcome\")\n",
    "    measurement_unit: Optional[str] = Field(None, description=\"Unit of measurement\")\n",
    "    normal_range: Optional[str] = Field(None, description=\"Normal or target range when applicable\")\n",
    "    baseline_value: Optional[float] = Field(None, description=\"Baseline measurement value\")\n",
    "    post_treatment_value: Optional[float] = Field(None, description=\"Post-treatment measurement value\")\n",
    "    change_from_baseline: Optional[float] = Field(None, description=\"Change from baseline\")\n",
    "    p_value: Optional[float] = Field(None, description=\"Statistical significance if reported\")\n",
    "    confidence_interval: Optional[str] = Field(None, description=\"95% confidence interval\")\n",
    "    effect_size: Optional[float] = Field(None, description=\"Standardized effect size\")\n",
    "    \n",
    "    class Config:\n",
    "        json_schema_extra = {\n",
    "            \"examples\": [\n",
    "                {\n",
    "                    \"clinical_outcome_id\": \"OUT001\",\n",
    "                    \"name\": \"HbA1c\",\n",
    "                    \"category\": \"Glycemic control\",\n",
    "                    \"measurement_unit\": \"%\",\n",
    "                    \"normal_range\": \"<7.0%\",\n",
    "                    \"baseline_value\": 8.5,\n",
    "                    \"post_treatment_value\": 7.2,\n",
    "                    \"change_from_baseline\": -1.3,\n",
    "                    \"p_value\": 0.001,\n",
    "                    \"confidence_interval\": \"[-1.8, -0.8]\",\n",
    "                    \"effect_size\": -0.8\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "\n",
    "class MedicalCondition(BaseModel):\n",
    "    \"\"\"Medical conditions and comorbidities studied\"\"\"\n",
    "    \n",
    "    medical_condition_id: str = Field(..., description=\"Unique identifier for the condition\")\n",
    "    name: str = Field(..., description=\"Name of the medical condition\")\n",
    "    category: str = Field(..., description=\"Category of condition\")\n",
    "    severity: Optional[str] = Field(None, description=\"Severity or stage when specified\")\n",
    "    icd10_code: Optional[str] = Field(None, description=\"ICD-10 code when available\")\n",
    "    duration: Optional[str] = Field(None, description=\"Duration of condition if specified\")\n",
    "    prevalence: Optional[float] = Field(None, description=\"Prevalence in study population\")\n",
    "    \n",
    "    class Config:\n",
    "        json_schema_extra = {\n",
    "            \"examples\": [\n",
    "                {\n",
    "                    \"medical_condition_id\": \"COND001\",\n",
    "                    \"name\": \"Type 2 diabetes mellitus\",\n",
    "                    \"category\": \"Primary condition\", \n",
    "                    \"severity\": \"moderate\",\n",
    "                    \"icd10_code\": \"E11\",\n",
    "                    \"duration\": \"5-10 years\",\n",
    "                    \"prevalence\": 100.0\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "\n",
    "class StudyPopulation(BaseModel):\n",
    "    \"\"\"Patient populations and demographics in research studies\"\"\"\n",
    "    \n",
    "    study_population_id: str = Field(..., description=\"Unique identifier for the population\")\n",
    "    description: str = Field(..., description=\"Description of the population\")\n",
    "    age_range: Optional[str] = Field(None, description=\"Age range\")\n",
    "    mean_age: Optional[float] = Field(None, description=\"Mean age in years\")\n",
    "    male_percentage: Optional[float] = Field(None, description=\"Percentage of male gender participants\")\n",
    "    female_percentage: Optional[float] = Field(None, description=\"Percentage of female gender participants\")\n",
    "    other_gender_percentage: Optional[float] = Field(None, description=\"Percentage of participants that identify as another gender\")\n",
    "    sample_size: Optional[int] = Field(None, description=\"Number of participants\")\n",
    "    study_type: str = Field(..., description=\"Type of study\")\n",
    "    location: Optional[str] = Field(None, description=\"Geographic location of study\")\n",
    "    inclusion_criteria: Optional[List[str]] = Field(None, description=\"Key inclusion criteria\")\n",
    "    exclusion_criteria: Optional[List[str]] = Field(None, description=\"Key exclusion criteria\")\n",
    "    study_duration: Optional[str] = Field(None, description=\"Duration of study\")\n",
    "    \n",
    "    class Config:\n",
    "        json_schema_extra = {\n",
    "            \"examples\": [\n",
    "                {\n",
    "                    \"study_population_id\": \"POP001\",\n",
    "                    \"description\": \"Adults with T2DM and schizophrenia\",\n",
    "                    \"age_range\": \"18-65 years\",\n",
    "                    \"mean_age\": 43.8,\n",
    "                    \"female_percentage\": 47.0,\n",
    "                    \"male_percentage\": 53.0,\n",
    "                    \"sample_size\": 354,\n",
    "                    \"study_type\": \"Observational study\",\n",
    "                    \"location\": \"Denmark\",\n",
    "                    \"inclusion_criteria\": [\"Type 2 diabetes diagnosis\", \"Schizophrenia diagnosis\", \"Age ≥18\"],\n",
    "                    \"study_duration\": \"12 months\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "\n",
    "# Relationship classes\n",
    "class StudyMedicationUsesMedication(BaseModel):\n",
    "    \"\"\"Links study medication to base medication\"\"\"\n",
    "    study_medication_id: str\n",
    "    medication_name: str\n",
    "\n",
    "\n",
    "class StudyMedicationProducesClinicalOutcome(BaseModel):\n",
    "    \"\"\"Links study medication usage to clinical outcomes\"\"\"\n",
    "    study_medication_id: str\n",
    "    clinical_outcome_name: str\n",
    "\n",
    "\n",
    "class StudyPopulationHasMedicalCondition(BaseModel):\n",
    "    \"\"\"Relationship between study population and medical conditions\"\"\"\n",
    "    study_population_id: str\n",
    "    medical_condition_name: str\n",
    "\n",
    "\n",
    "class StudyPopulationReceivesStudyMedication(BaseModel):\n",
    "    \"\"\"Relationship between study population and study medication\"\"\"\n",
    "    study_population_id: str\n",
    "    study_medication_id: str\n",
    "\n",
    "\n",
    "class StudyPopulationHasOutcome(BaseModel):\n",
    "    \"\"\"Direct relationship between population and outcomes (for population-level measurements)\"\"\"\n",
    "    study_population_id: str\n",
    "    clinical_outcome_name: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our knowledge graph data model looks like this \n",
    "\n",
    "IMAGE OF DATA MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity Extraction LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using [OpenAI](https://platform.openai.com/docs/overview) and the [Instructor](https://python.useinstructor.com/) library to perform our entity extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AsyncOpenAI\n",
    "import instructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = instructor.from_openai(AsyncOpenAI())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def extract_entities_from_text_chunk(text_chunk: str) -> list:\n",
    "    response = await client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a healthcare research expert that is responsible for extracting detailed entities from PubMed articles. You are provided a graph data model schema and must extract entities and relationships to populate a knowledge graph.\"},\n",
    "            {\"role\": \"user\", \"content\": text_chunk}\n",
    "        ],\n",
    "        response_model=list[Medication | StudyMedication | StudyMedicationUsesMedication],\n",
    "    )\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def extract_entities_from_chunk_nodes(chunk_nodes: list[Chunk]) -> list[tuple[str, list[Any]]]:\n",
    "    \"\"\"Process a list of Chunk nodes and return the entities found in each chunk.\"\"\"\n",
    "\n",
    "    # Create tasks for all nodes\n",
    "    # order is maintained\n",
    "    tasks = [extract_entities_from_text_chunk(chunk.text) for chunk in chunk_nodes]\n",
    "\n",
    "    # Execute all tasks concurrently\n",
    "    extraction_results = await asyncio.gather(*tasks)\n",
    "\n",
    "    # Return chunk_id paired with its entities\n",
    "    return [(chunk.id, entities) for chunk, entities in zip(chunk_nodes, extraction_results)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "al Science, Faculty of Medicine, Universitas Airlangga, \n",
      "Surabaya, Indonesia. fahrul.nurkolis.mail@gmail.com.\n",
      "(11)Medical Research Center of Indonesia, Surabaya, East Java, Indonesia. \n",
      "fahrul.nurkolis.mail@gmail.com.\n",
      "\n",
      "BACKGROUND: The global rise in obesity and type 2 diabetes highlights the need \n",
      "for safe and effective therapeutic interventions. Enhalus acoroides is a \n",
      "tropical seagrass rich in carotenoids and other bioactives. Its potential for \n",
      "metabolic regulation has been suggested in vitro, but in vivo efficacy and \n",
      "molecular mechanisms remain unexplored. This study aimed to evaluate the \n",
      "anti-obesity and anti-diabetic effects of Enhalus acoroides extract (SEAE) in a \n",
      "zebrafish model of diet- and glucose-induced metabolic dysfunction.\n",
      "METHODS: Adult zebrafish were subjected to overfeeding and glucose immersion, \n",
      "after overfeeding and 14 days of glucose immersion to induce diabetes, adult \n",
      "zebrafish were randomized into three groups: untreated diabetic, SEAE-treated \n",
      "(5 mg/L), and \n"
     ]
    }
   ],
   "source": [
    "with open(\"pubmed_abstracts.txt\", \"r\") as f:\n",
    "    text = f.read()[1500:2500]\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "ents = await extract_entities_from_text_chunk(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Medication(medication_id='MED002', name='Enhalus acoroides extract', medication_class='Natural extract', mechanism=None, generic_name='SEAE', brand_names=None, approval_status=None),\n",
       " StudyMedication(study_medication_id='STUDY_MED002', medication_id='MED002', dosage='5 mg/L', route=None, frequency=None, treatment_duration=None, treatment_arm='SEAE-treated group', comparator=None, adherence_rate=None, formulation=None)]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now defined \n",
    "* Lexical and domain data models\n",
    "* Partitioning and chunking logic for articles\n",
    "* Entity extraction logic for chunks\n",
    "\n",
    "It is now time to define our ingestion logic. We will run ingest in three stages \n",
    "\n",
    "1. Load lexical graph\n",
    "2. Embed lexical graph Chunk nodes\n",
    "3. Extract domain / entity graph from lexical graph\n",
    "\n",
    "Decoupling these stages allows us easily make changes as we iterate our ingestion process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from neo4j import GraphDatabase, Driver, RoutingControl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = GraphDatabase.driver(os.getenv(\"NEO4J_URI\", \"bolt://localhost:7687\"), \n",
    "                              auth=(os.getenv(\"NEO4J_USER\", \"neo4j\"), os.getenv(\"NEO4J_PASSWORD\", \"password\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingest Lexical Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexical_constraints = [\n",
    "    \"CREATE CONSTRAINT document_id IF NOT EXISTS FOR (n:Document) REQUIRE n.id IS NODE KEY\",\n",
    "    \"CREATE CONSTRAINT document_name IF NOT EXISTS FOR (n:Document) REQUIRE n.name IS NODE KEY\",\n",
    "    \"CREATE CONSTRAINT chunk_id IF NOT EXISTS FOR (n:Chunk) REQUIRE n.id IS NODE KEY\"\n",
    "]\n",
    "\n",
    "\n",
    "def create_lexical_constraints(driver: Driver) -> None:\n",
    "    for constraint in lexical_constraints:\n",
    "        driver.execute_query(constraint, database_=os.getenv(\"NEO4J_DATABASE\", \"neo4j\"), routing_=RoutingControl.WRITE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lexical_document_nodes(driver: Driver, document_nodes: list[Document]) -> None:\n",
    "    \"\"\"Load document nodes into the lexical graph\"\"\"\n",
    "    records = [record.model_dump() for record in document_nodes]\n",
    "    query = \"\"\"\n",
    "        UNWIND $records AS record\n",
    "        MERGE (n:Document {id: record.id})\n",
    "        ON CREATE SET n.name = record.name, n.source = record.source\n",
    "    \"\"\"\n",
    "    driver.execute_query(query, \n",
    "                         records=records, \n",
    "                         database_=os.getenv(\"NEO4J_DATABASE\", \"neo4j\"), \n",
    "                         routing_=RoutingControl.WRITE)\n",
    "\n",
    "def load_lexical_chunk_nodes(driver: Driver, chunk_nodes: list[Chunk]) -> None:\n",
    "    \"\"\"Load chunk nodes into the lexical graph\"\"\"\n",
    "    records = [record.model_dump() for record in chunk_nodes]\n",
    "    query = \"\"\"\n",
    "        UNWIND $records AS record\n",
    "        MERGE (n:Chunk {id: record.id})\n",
    "        ON CREATE SET n.text = record.text\n",
    "    \"\"\"\n",
    "    driver.execute_query(query, \n",
    "                         records=records, \n",
    "                         database_=os.getenv(\"NEO4J_DATABASE\", \"neo4j\"), \n",
    "                         routing_=RoutingControl.WRITE)\n",
    "\n",
    "def load_lexical_chunk_part_of_document_relationships(driver: Driver, chunk_part_of_document_relationships: list[ChunkPartOfDocument]) -> None:\n",
    "    \"\"\"Load Chunk - PART_OF -> Document relationships into the lexical graph\"\"\"\n",
    "    records = [record.model_dump() for record in chunk_part_of_document_relationships]\n",
    "    query = \"\"\"\n",
    "        UNWIND $records AS record\n",
    "        MATCH (c:Chunk {id: record.chunk_id}), (d:Document {id: record.document_id})\n",
    "        MERGE (c)-[:PART_OF]->(d)\n",
    "    \"\"\"\n",
    "    driver.execute_query(query, \n",
    "                         records=records, \n",
    "                         database_=os.getenv(\"NEO4J_DATABASE\", \"neo4j\"), \n",
    "                         routing_=RoutingControl.WRITE)\n",
    "\n",
    "def load_lexical_graph(driver: Driver, lexical_ingest_records: dict[str, list[Document | Chunk | ChunkPartOfDocument]]) -> None:\n",
    "    \"\"\"Load the lexical graph\"\"\"\n",
    "    print(\"Creating Constraints\")\n",
    "    create_lexical_constraints(driver)\n",
    "\n",
    "    print(f\"Loading Document nodes\")\n",
    "    load_lexical_document_nodes(driver, [lexical_ingest_records.get(\"nodes\")[0]])\n",
    "\n",
    "    print(f\"Loading Chunk nodes\")\n",
    "    load_lexical_chunk_nodes(driver, lexical_ingest_records.get(\"nodes\")[1:])\n",
    "    \n",
    "    print(f\"Loading Chunk - PART_OF -> Document relationships\")\n",
    "    load_lexical_chunk_part_of_document_relationships(driver, lexical_ingest_records.get(\"relationships\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libmagic is unavailable but assists in filetype detection. Please consider installing libmagic for better results.\n"
     ]
    }
   ],
   "source": [
    "lexical_ingest_records = process_article(\"pubmed_abstracts.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the first few records "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='a5ca5246-9454-42c6-88b4-93fadd9c439d', name='pubmed_abstracts.txt', source='pubmed'),\n",
       " Chunk(id='c7575a02b7776f6183bcb0c3aa2b3a58', text='1. Diabetol Metab Syndr. 2025 Jun 21;17(1):235. doi: 10.1186/s13098-025-01823-4.\\n\\nSeagrass Enhalus acoroides extract mitigates obesity and diabetes via GLP-1, PPARγ, SREBP-1c modulation and gut microbiome restoration in diabetic zebrafish.\\n\\nKadharusman MM(1), Syahputra RA(2), Kurniawan R(3), Hadinata E(4), Tjandrawinata RR(5), Taslim NA(6), Romano R(7), Santini A(8), Nurkolis F(9)(10)(11).'),\n",
       " Chunk(id='aaf28f4d0b350bd4c312418709797fd5', text='Author information: (1)Faculty of Medicine, Universitas Indonesia, Jakarta, Indonesia. (2)Department of Pharmacology, Faculty of Pharmacy, Universitas Sumatera Utara, Medan, 20155, Indonesia. (3)Graduate School of Medicine, Faculty of Medicine, Hasanuddin University, Makassar, Indonesia. (4)Faculty of Medicine, Ciputra University of Surabaya, Surabaya, 60219, Indonesia. (5)Center for Pharmaceutical and Nutraceutical Research and Policy, Faculty of Biotechnology, Atma Jaya Catholic University of')]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexical_ingest_records.get(\"nodes\")[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the records into the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Constraints\n",
      "Loading Document nodes\n",
      "Loading Chunk nodes\n",
      "Loading Chunk - PART_OF -> Document relationships\n"
     ]
    }
   ],
   "source": [
    "load_lexical_graph(driver, lexical_ingest_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embed Lexical Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will read Chunk nodes from the graph that don't have embedding properties yet. \n",
    "\n",
    "We will then embed the Chunk text property and add the embedding as a property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_index = ...\n",
    "\n",
    "def create_vector_index(driver: Driver) -> None:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(driver: Driver) -> None:\n",
    "    ...\n",
    "\n",
    "def embed_lexical_graph(driver: Driver) -> None:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Entities from Lexical Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now perform entity extraction on the Chunk nodes to augment and connect to our domain graph containing patient journey information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_constraints = [\n",
    "    \"CREATE CONSTRAINT medication_id IF NOT EXISTS FOR (n:Medication) REQUIRE n.id IS UNIQUE\",\n",
    "    \"CREATE CONSTRAINT medication_name IF NOT EXISTS FOR (n:Medication) REQUIRE n.name IS NODE KEY\",\n",
    "    \"CREATE CONSTRAINT study_medication_id IF NOT EXISTS FOR (n:StudyMedication) REQUIRE n.id IS UNIQUE\",\n",
    "    \"CREATE CONSTRAINT medical_condition_id IF NOT EXISTS FOR (n:MedicalCondition) REQUIRE n.id IS UNIQUE\",\n",
    "    \"CREATE CONSTRAINT medical_condition_name IF NOT EXISTS FOR (n:MedicalCondition) REQUIRE n.name IS NODE KEY\",\n",
    "    \"CREATE CONSTRAINT study_population_id IF NOT EXISTS FOR (n:StudyPopulation) REQUIRE n.id IS UNIQUE\",\n",
    "    \"CREATE CONSTRAINT study_population_name IF NOT EXISTS FOR (n:StudyPopulation) REQUIRE n.name IS NODE KEY\",\n",
    "    \"CREATE CONSTRAINT study_outcome_id IF NOT EXISTS FOR (n:StudyOutcome) REQUIRE n.id IS UNIQUE\",\n",
    "    \"CREATE CONSTRAINT study_outcome_name IF NOT EXISTS FOR (n:StudyOutcome) REQUIRE n.name IS NODE KEY\",\n",
    "]\n",
    "\n",
    "def create_entity_constraints(driver: Driver) -> None:\n",
    "    \"\"\"Create constraints for the entity graph\"\"\"\n",
    "\n",
    "    driver.execute_query(entity_constraints, \n",
    "                         database_=os.getenv(\"NEO4J_DATABASE\", \"neo4j\"), \n",
    "                         routing_=RoutingControl.WRITE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunk_nodes_to_process(driver: Driver, article_name: str) -> list[Chunk]:\n",
    "    \"\"\"\n",
    "    Retrieve Chunk node id and text from the database that have a relationship to the Document with the article name provided.\n",
    "    \"\"\"\n",
    "\n",
    "    query = \"\"\"\n",
    "    MATCH (d:Document {name: $article_name})<-[:PART_OF]-(c:Chunk)\n",
    "    RETURN c.id as id, c.text as text\n",
    "    \"\"\"\n",
    "\n",
    "    result = driver.execute_query(query, \n",
    "                                  {\"article_name\": article_name}, \n",
    "                                  database_=os.getenv(\"NEO4J_DATABASE\", \"neo4j\"), \n",
    "                                  routing_=RoutingControl.READ, \n",
    "                                  result_transformer_=lambda x: [Chunk(**args) for args in x.data()])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENTITY_LABELS = {\n",
    "    \"Medication\", \n",
    "    \"StudyMedication\",\n",
    "    \"MedicalCondition\",\n",
    "    \"StudyPopulation\",\n",
    "    \"ClinicalOutcome\",\n",
    "}\n",
    "\n",
    "ENTITY_RELS = {\n",
    "    \"StudyMedicationUsesMedication\",\n",
    "    \"StudyMedicationProducesOutcome\",\n",
    "    \"StudyPopulationHasMedicalCondition\",\n",
    "    \"StudyPopulationReceivesStudyMedication\",\n",
    "    \"StudyPopulationHasOutcome\",\n",
    "}\n",
    "\n",
    "def prepare_entities_for_ingestion(entities: list[tuple[str, list[Any]]]) -> dict[str, list[dict[str, Any]]]:\n",
    "    \"\"\"\n",
    "    Prepare entities for ingestion into the graph.\n",
    "    This function takes the results of the `get_chunk_nodes_to_process` function and returns a dictionary of entity label to list of entities.\n",
    "    \"\"\"\n",
    "\n",
    "    records_node_dict = {lbl: list() for lbl in ENTITY_LABELS}\n",
    "    records_rel_dict = {lbl: list() for lbl in ENTITY_RELS}\n",
    "\n",
    "    for chunk_id, entities in entities:\n",
    "        for entity in entities:\n",
    "            to_add = entity.model_dump()\n",
    "            to_add.update({\"chunk_id\": chunk_id})\n",
    "            # nodes\n",
    "            if entity.__class__.__name__ in ENTITY_LABELS:\n",
    "                records_node_dict[entity.__class__.__name__].append(to_add)\n",
    "            # rels\n",
    "            elif entity.__class__.__name__ in ENTITY_RELS:\n",
    "                records_rel_dict[entity.__class__.__name__].append(to_add)\n",
    "            else:\n",
    "                print(f\"Unknown entity type: {entity.__class__.__name__}\")\n",
    "\n",
    "    return {\"nodes\": records_node_dict, \"relationships\": records_rel_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 171 chunks to process\n",
      "First chunk: id='c7575a02b7776f6183bcb0c3aa2b3a58' text='1. Diabetol Metab Syndr. 2025 Jun 21;17(1):235. doi: 10.1186/s13098-025-01823-4.\\n\\nSeagrass Enhalus acoroides extract mitigates obesity and diabetes via GLP-1, PPARγ, SREBP-1c modulation and gut microbiome restoration in diabetic zebrafish.\\n\\nKadharusman MM(1), Syahputra RA(2), Kurniawan R(3), Hadinata E(4), Tjandrawinata RR(5), Taslim NA(6), Romano R(7), Santini A(8), Nurkolis F(9)(10)(11).'\n"
     ]
    }
   ],
   "source": [
    "chunks_to_process = get_chunk_nodes_to_process(driver, \"pubmed_abstracts.txt\")\n",
    "print(f\"Found {len(chunks_to_process)} chunks to process\")\n",
    "print(f\"First chunk: {chunks_to_process[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_ingest_records = await extract_entities_from_chunk_nodes(chunks_to_process[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('c7575a02b7776f6183bcb0c3aa2b3a58',\n",
       "  [Medication(medication_id='MED002', name='Seagrass Enhalus acoroides extract', medication_class='Natural extract', mechanism='GLP-1, PPARγ, SREBP-1c modulation and gut microbiome restoration', generic_name=None, brand_names=None, approval_status=None)]),\n",
       " ('aaf28f4d0b350bd4c312418709797fd5', []),\n",
       " ('def7de5c464d6254bdaa2d73b86034eb',\n",
       "  [Medication(medication_id='MED001', name='Semaglutide', medication_class='GLP-1 receptor agonist', mechanism='GLP-1 receptor activation', generic_name='semaglutide', brand_names=['Ozempic', 'Wegovy', 'Rybelsus'], approval_status='FDA approved'),\n",
       "   StudyMedication(study_medication_id='STUDY_MED001', dosage='1.0 mg', route='subcutaneous', frequency='weekly', treatment_duration='12 weeks', treatment_arm='Active treatment group', comparator='placebo', adherence_rate=85.5, formulation='pre-filled pen'),\n",
       "   StudyMedicationUsesMedication(study_medication_id='STUDY_MED001', medication_name='Semaglutide')]),\n",
       " ('e0313766b618ceaaf67ad271da664657', []),\n",
       " ('13e0b5fa31fac4fc45f154b8a820a39c',\n",
       "  [Medication(medication_id='MED002', name='Enhalus acoroides Extract', medication_class='Herbal medication', mechanism=None, generic_name='SEAE', brand_names=None, approval_status=None)]),\n",
       " ('a367e70b651483e37ff05b067c18204f',\n",
       "  [Medication(medication_id='MED002', name='Metformin', medication_class='Biguanide', mechanism='Decreases hepatic glucose production and increases insulin sensitivity', generic_name='metformin', brand_names=['Glucophage', 'Glumetza'], approval_status='FDA approved'),\n",
       "   StudyMedication(study_medication_id='STUDY_MED002', dosage='3.3 mg/L', route='water immersion', frequency=None, treatment_duration='20 days', treatment_arm='Metformin-treated group', comparator='untreated diabetic', adherence_rate=None, formulation=None),\n",
       "   StudyMedication(study_medication_id='STUDY_MED003', dosage='5 mg/L', route='water immersion', frequency=None, treatment_duration='20 days', treatment_arm='SEAE-treated group', comparator='untreated diabetic', adherence_rate=None, formulation=None),\n",
       "   StudyMedicationUsesMedication(study_medication_id='STUDY_MED002', medication_name='Metformin')]),\n",
       " ('3965d94b1bde07e1076d839475c2d987',\n",
       "  [Medication(medication_id='MED002', name='SEAE', medication_class='Herbal extract', mechanism='Upregulation of GLP-1 and downregulation of PPARγ and SREBP-1c', generic_name=None, brand_names=None, approval_status=None),\n",
       "   StudyMedication(study_medication_id='STUDY_MED002', dosage=None, route=None, frequency=None, treatment_duration=None, treatment_arm='SEAE treatment group', comparator='Metformin', adherence_rate=None, formulation=None)]),\n",
       " ('0b59be3d8bb5ff8bb44669c8708e2031',\n",
       "  [Medication(medication_id='MED002', name='SEAE', medication_class='Marine-derived therapeutic', mechanism='Modulating key metabolic pathways and restoring gut microbial homeostasis', generic_name=None, brand_names=None, approval_status=None)])]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_ingest_records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingest Entities Into Knowledge Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions load the extracted entities and relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_medication_nodes(driver: Driver, medications: list[Medication]) -> None:\n",
    "    \"\"\"Ingest medication nodes into the graph\"\"\"\n",
    "\n",
    "    query = \"\"\"\n",
    "    UNWIND $medications AS medication\n",
    "    MERGE (n:Medication {id: medication.medication_id, name: medication.name})\n",
    "    SET n.medication_class = COALESCE(n.medication_class, medication.medication_class), \n",
    "        n.mechanism = COALESCE(n.mechanism, medication.mechanism), \n",
    "        n.generic_name = COALESCE(n.generic_name, medication.generic_name), \n",
    "        n.brand_names = COALESCE(n.brand_names, medication.brand_names), \n",
    "        n.approval_status = COALESCE(n.approval_status, medication.approval_status)\n",
    "    \"\"\"\n",
    "\n",
    "    driver.execute_query(query, \n",
    "                         {\"medications\": medications}, \n",
    "                         database_=os.getenv(\"NEO4J_DATABASE\", \"neo4j\"), \n",
    "                         routing_=RoutingControl.WRITE)\n",
    "\n",
    "def ingest_study_medication_nodes(driver: Driver, study_medications: list[StudyMedication]) -> None:\n",
    "    \"\"\"Ingest study medication nodes into the graph\"\"\"\n",
    "\n",
    "    query = \"\"\"\n",
    "    UNWIND $study_medications AS study_medication\n",
    "    MERGE (n:StudyMedication {id: study_medication.study_medication_id})\n",
    "    SET n.dosage = COALESCE(n.dosage, study_medication.dosage), \n",
    "        n.route = COALESCE(n.route, study_medication.route), \n",
    "        n.frequency = COALESCE(n.frequency, study_medication.frequency), \n",
    "        n.treatment_duration = COALESCE(n.treatment_duration, study_medication.treatment_duration), \n",
    "        n.treatment_arm = COALESCE(n.treatment_arm, study_medication.treatment_arm), \n",
    "        n.comparator = COALESCE(n.comparator, study_medication.comparator), \n",
    "        n.adherence_rate = COALESCE(n.adherence_rate, study_medication.adherence_rate), \n",
    "        n.formulation = COALESCE(n.formulation, study_medication.formulation)\n",
    "    \"\"\"\n",
    "\n",
    "    driver.execute_query(query, \n",
    "                         {\"study_medications\": study_medications}, \n",
    "                         database_=os.getenv(\"NEO4J_DATABASE\", \"neo4j\"), \n",
    "                         routing_=RoutingControl.WRITE)\n",
    "\n",
    "def ingest_clinical_outcome_nodes(driver: Driver, clinical_outcomes: list[ClinicalOutcome]) -> None:\n",
    "    \"\"\"Ingest clinical outcome nodes into the graph\"\"\"\n",
    "\n",
    "    query = \"\"\"\n",
    "    UNWIND $clinical_outcomes AS clinical_outcome\n",
    "    MERGE (n:ClinicalOutcome {id: clinical_outcome.clinical_outcome_id})\n",
    "    SET n.category = COALESCE(n.category, clinical_outcome.category), \n",
    "        n.measurement_unit = COALESCE(n.measurement_unit, clinical_outcome.measurement_unit), \n",
    "        n.normal_range = COALESCE(n.normal_range, clinical_outcome.normal_range), \n",
    "        n.baseline_value = COALESCE(n.baseline_value, clinical_outcome.baseline_value), \n",
    "        n.post_treatment_value = COALESCE(n.post_treatment_value, clinical_outcome.post_treatment_value), \n",
    "        n.change_from_baseline = COALESCE(n.change_from_baseline, clinical_outcome.change_from_baseline), \n",
    "        n.p_value = COALESCE(n.p_value, clinical_outcome.p_value), \n",
    "        n.confidence_interval = COALESCE(n.confidence_interval, clinical_outcome.confidence_interval), \n",
    "        n.effect_size = COALESCE(n.effect_size, clinical_outcome.effect_size)\n",
    "    \"\"\"\n",
    "\n",
    "    driver.execute_query(query, \n",
    "                         {\"clinical_outcomes\": clinical_outcomes}, \n",
    "                         database_=os.getenv(\"NEO4J_DATABASE\", \"neo4j\"), \n",
    "                         routing_=RoutingControl.WRITE)\n",
    "\n",
    "def ingest_medical_condition_nodes(driver: Driver, medical_conditions: list[MedicalCondition]) -> None:\n",
    "    \"\"\"Ingest medical condition nodes into the graph\"\"\"\n",
    "\n",
    "    query = \"\"\"\n",
    "    UNWIND $medical_conditions AS medical_condition\n",
    "    MERGE (n:MedicalCondition {id: medical_condition.medical_condition_id, name: medical_condition.name})\n",
    "    SET n.category = COALESCE(n.category, medical_condition.category), \n",
    "        n.severity = COALESCE(n.severity, medical_condition.severity), \n",
    "        n.icd10_code = COALESCE(n.icd10_code, medical_condition.icd10_code), \n",
    "        n.duration = COALESCE(n.duration, medical_condition.duration), \n",
    "        n.prevalence = COALESCE(n.prevalence, medical_condition.prevalence)\n",
    "    \"\"\"\n",
    "\n",
    "    driver.execute_query(query, \n",
    "                         {\"medical_conditions\": medical_conditions}, \n",
    "                         database_=os.getenv(\"NEO4J_DATABASE\", \"neo4j\"), \n",
    "                         routing_=RoutingControl.WRITE)\n",
    "\n",
    "def ingest_study_population_nodes(driver: Driver, study_populations: list[StudyPopulation]) -> None:\n",
    "    \"\"\"Ingest study population nodes into the graph\"\"\"\n",
    "\n",
    "    query = \"\"\"\n",
    "    UNWIND $study_populations AS study_population\n",
    "    MERGE (n:StudyPopulation {id: study_population.study_population_id})\n",
    "    SET n.description = COALESCE(n.description, study_population.description), \n",
    "        n.age_range = COALESCE(n.age_range, study_population.age_range), \n",
    "        n.mean_age = COALESCE(n.mean_age, study_population.mean_age), \n",
    "        n.male_percentage = COALESCE(n.male_percentage, study_population.male_percentage), \n",
    "        n.female_percentage = COALESCE(n.female_percentage, study_population.female_percentage), \n",
    "        n.other_gender_percentage = COALESCE(n.other_gender_percentage, study_population.other_gender_percentage), \n",
    "        n.sample_size = COALESCE(n.sample_size, study_population.sample_size), \n",
    "        n.study_type = COALESCE(n.study_type, study_population.study_type), \n",
    "        n.location = COALESCE(n.location, study_population.location), \n",
    "        n.inclusion_criteria = COALESCE(n.inclusion_criteria, study_population.inclusion_criteria), \n",
    "        n.exclusion_criteria = COALESCE(n.exclusion_criteria, study_population.exclusion_criteria), \n",
    "        n.study_duration = COALESCE(n.study_duration, study_population.study_duration)\n",
    "    \"\"\"\n",
    "\n",
    "    driver.execute_query(query, \n",
    "                         {\"study_populations\": study_populations}, \n",
    "                         database_=os.getenv(\"NEO4J_DATABASE\", \"neo4j\"), \n",
    "                         routing_=RoutingControl.WRITE)\n",
    "\n",
    "\n",
    "\n",
    "def ingest_study_medication_uses_medication_relationships(driver: Driver, study_medication_uses_medications: list[StudyMedicationUsesMedication]) -> None:\n",
    "    \"\"\"Links study medication to base medication\"\"\"\n",
    "\n",
    "    query = \"\"\"\n",
    "    UNWIND $study_medication_uses_medications AS study_medication_uses_medication\n",
    "    MATCH (s:StudyMedication {id: study_medication_uses_medication.study_medication_id}), (m:Medication {name: study_medication_uses_medication.medication_name})\n",
    "    MERGE (s)-[:USES]->(m)\n",
    "    \"\"\"\n",
    "\n",
    "    driver.execute_query(query, \n",
    "                         {\"study_medication_uses_medications\": study_medication_uses_medications}, \n",
    "                         database_=os.getenv(\"NEO4J_DATABASE\", \"neo4j\"), \n",
    "                         routing_=RoutingControl.WRITE)\n",
    "\n",
    "def ingest_study_medication_produces_clinical_outcome_relationships(driver: Driver, study_medication_produces_clinical_outcomes: list[StudyMedicationProducesClinicalOutcome]) -> None:\n",
    "    \"\"\"Links study medication usage to clinical outcomes\"\"\"\n",
    "\n",
    "    query = \"\"\"\n",
    "    UNWIND $study_medication_produces_clinical_outcomes AS study_medication_produces_clinical_outcome\n",
    "    MATCH (s:StudyMedication {id: study_medication_produces_clinical_outcome.study_medication_id}), (o:ClinicalOutcome {name: study_medication_produces_clinical_outcome.clinical_outcome_name})\n",
    "    MERGE (s)-[:PRODUCES]->(o)\n",
    "    \"\"\"\n",
    "\n",
    "    driver.execute_query(query, \n",
    "                         {\"study_medication_produces_clinical_outcomes\": study_medication_produces_clinical_outcomes}, \n",
    "                         database_=os.getenv(\"NEO4J_DATABASE\", \"neo4j\"), \n",
    "                         routing_=RoutingControl.WRITE)\n",
    "\n",
    "\n",
    "\n",
    "def ingest_study_population_has_medical_condition_relationships(driver: Driver, study_population_has_medical_conditions: list[StudyPopulationHasMedicalCondition]) -> None:\n",
    "    \"\"\"Links study population to medical condition\"\"\"\n",
    "    \n",
    "    query = \"\"\"\n",
    "    UNWIND $study_population_has_medical_conditions AS study_population_has_medical_condition\n",
    "    MATCH (s:StudyPopulation {id: study_population_has_medical_condition.study_population_id}), (m:MedicalCondition {name: study_population_has_medical_condition.medical_condition_name})\n",
    "    MERGE (s)-[:HAS]->(m)\n",
    "    \"\"\" \n",
    "\n",
    "    driver.execute_query(query, \n",
    "                         {\"study_population_has_medical_conditions\": study_population_has_medical_conditions}, \n",
    "                         database_=os.getenv(\"NEO4J_DATABASE\", \"neo4j\"), \n",
    "                         routing_=RoutingControl.WRITE)\n",
    "\n",
    "\n",
    "def ingest_study_population_receives_study_medication_relationships(driver: Driver, study_population_receives_study_medications: list[StudyPopulationReceivesStudyMedication]) -> None:\n",
    "    \"\"\"Links study population to study medication\"\"\"\n",
    "\n",
    "    query = \"\"\"\n",
    "    UNWIND $study_population_receives_study_medications AS study_population_receives_study_medication\n",
    "    MATCH (s:StudyPopulation {id: study_population_receives_study_medication.study_population_id}), (m:StudyMedication {id: study_population_receives_study_medication.study_medication_id})\n",
    "    MERGE (s)-[:RECEIVES]->(m)\n",
    "    \"\"\"\n",
    "\n",
    "    driver.execute_query(query, \n",
    "                         {\"study_population_receives_study_medications\": study_population_receives_study_medications}, \n",
    "                         database_=os.getenv(\"NEO4J_DATABASE\", \"neo4j\"), \n",
    "                         routing_=RoutingControl.WRITE)\n",
    "\n",
    "def ingest_study_population_has_clinical_outcome_relationships(driver: Driver, study_population_has_outcomes: list[StudyPopulationHasOutcome]) -> None:\n",
    "    \"\"\"Links study population to outcome\"\"\"\n",
    "\n",
    "    query = \"\"\"\n",
    "    UNWIND $study_population_has_outcomes AS study_population_has_outcome\n",
    "    MATCH (s:StudyPopulation {id: study_population_has_outcome.study_population_id}), (o:ClinicalOutcome {name: study_population_has_outcome.clinical_outcome_name})\n",
    "    MERGE (s)-[:HAS_OUTCOME]->(o)\n",
    "    \"\"\"\n",
    "\n",
    "    driver.execute_query(query, \n",
    "                         {\"study_population_has_outcomes\": study_population_has_outcomes}, \n",
    "                         database_=os.getenv(\"NEO4J_DATABASE\", \"neo4j\"), \n",
    "                         routing_=RoutingControl.WRITE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions link the extracted entities with their text chunk nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_chunk_has_entity_medication_relationships(driver: Driver, records: list[dict[str, Any]]) -> None:\n",
    "    \"\"\"Ingest document has entity medication relationships into the graph\"\"\"\n",
    "\n",
    "    query = \"\"\"\n",
    "    UNWIND $records AS record\n",
    "    MATCH (c:Chunk {id: record.chunk_id}), (e:Medication {id: record.medication_id})\n",
    "    MERGE (c)-[:HAS_ENTITY]->(e)\n",
    "    \"\"\"\n",
    "\n",
    "    driver.execute_query(query, \n",
    "                         {\"records\": records}, \n",
    "                         database_=os.getenv(\"NEO4J_DATABASE\", \"neo4j\"), \n",
    "                         routing_=RoutingControl.WRITE)\n",
    "\n",
    "def ingest_chunk_has_entity_medical_condition_relationships(driver: Driver, records: list[dict[str, Any]]) -> None:\n",
    "    \"\"\"Ingest document has entity medical condition relationships into the graph\"\"\"\n",
    "\n",
    "    query = \"\"\"\n",
    "    UNWIND $records AS record\n",
    "    MATCH (c:Chunk {id: record.chunk_id}), (e:MedicalCondition {id: record.medical_condition_id})\n",
    "    MERGE (c)-[:HAS_ENTITY]->(e)\n",
    "    \"\"\"\n",
    "\n",
    "    driver.execute_query(query, \n",
    "                         {\"records\": records}, \n",
    "                         database_=os.getenv(\"NEO4J_DATABASE\", \"neo4j\"), \n",
    "                         routing_=RoutingControl.WRITE)\n",
    "\n",
    "def ingest_chunk_has_entity_study_medication_relationships(driver: Driver, records: list[dict[str, Any]]) -> None:\n",
    "    \"\"\"Ingest document has entity study medication relationships into the graph\"\"\"\n",
    "\n",
    "    query = \"\"\"\n",
    "    UNWIND $records AS record\n",
    "    MATCH (c:Chunk {id: record.chunk_id}), (e:StudyMedication {id: record.study_medication_id})\n",
    "    MERGE (c)-[:HAS_ENTITY]->(e)\n",
    "    \"\"\"\n",
    "\n",
    "    driver.execute_query(query,     \n",
    "                         {\"records\": records}, \n",
    "                         database_=os.getenv(\"NEO4J_DATABASE\", \"neo4j\"), \n",
    "                         routing_=RoutingControl.WRITE)\n",
    "\n",
    "def ingest_chunk_has_entity_study_population_relationships(driver: Driver, records: list[dict[str, Any]]) -> None:\n",
    "    \"\"\"Ingest document has entity study population relationships into the graph\"\"\"\n",
    "\n",
    "    query = \"\"\"\n",
    "    UNWIND $records AS record\n",
    "    MATCH (c:Chunk {id: record.chunk_id}), (e:StudyPopulation {id: record.study_population_id})\n",
    "    MERGE (c)-[:HAS_ENTITY]->(e)\n",
    "    \"\"\"\n",
    "\n",
    "    driver.execute_query(query, \n",
    "                         {\"records\": records}, \n",
    "                         database_=os.getenv(\"NEO4J_DATABASE\", \"neo4j\"), \n",
    "                         routing_=RoutingControl.WRITE)\n",
    "\n",
    "def ingest_chunk_has_entity_clinical_outcome_relationships(driver: Driver, records: list[dict[str, Any]]) -> None:\n",
    "    \"\"\"Ingest document has entity clinical outcome relationships into the graph\"\"\"\n",
    "\n",
    "    query = \"\"\"\n",
    "    UNWIND $records AS record\n",
    "    MATCH (c:Chunk {id: record.chunk_id}), (e:ClinicalOutcome {id: record.clinical_outcome_id})\n",
    "    MERGE (c)-[:HAS_ENTITY]->(e)\n",
    "    \"\"\"\n",
    "\n",
    "    driver.execute_query(query, \n",
    "                         {\"records\": records}, \n",
    "                         database_=os.getenv(\"NEO4J_DATABASE\", \"neo4j\"), \n",
    "                         routing_=RoutingControl.WRITE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_entities(driver: Driver, records_dict: dict[str, list[dict[str, Any]]]) -> None:\n",
    "    \"\"\"Ingest entities into the graph\"\"\"\n",
    "\n",
    "    nodes = records_dict.get(\"nodes\")\n",
    "    rels = records_dict.get(\"relationships\")\n",
    "\n",
    "    print(\"Ingesting Nodes\")\n",
    "    ingest_medication_nodes(driver, nodes.get(\"Medication\"))\n",
    "    ingest_study_medication_nodes(driver, nodes.get(\"StudyMedication\"))\n",
    "    ingest_medical_condition_nodes(driver, nodes.get(\"MedicalCondition\"))\n",
    "    ingest_study_population_nodes(driver, nodes.get(\"StudyPopulation\"))\n",
    "    ingest_clinical_outcome_nodes(driver, nodes.get(\"ClinicalOutcome\"))\n",
    "\n",
    "    print(\"Linking Nodes to Chunks\")\n",
    "    ingest_chunk_has_entity_medication_relationships(driver, nodes.get(\"Medication\"))\n",
    "    ingest_chunk_has_entity_medical_condition_relationships(driver, nodes.get(\"MedicalCondition\"))\n",
    "    ingest_chunk_has_entity_study_medication_relationships(driver, nodes.get(\"StudyMedication\"))\n",
    "    ingest_chunk_has_entity_study_population_relationships(driver, nodes.get(\"StudyPopulation\"))\n",
    "    ingest_chunk_has_entity_clinical_outcome_relationships(driver, nodes.get(\"ClinicalOutcome\"))\n",
    "\n",
    "    print(\"Ingesting Relationships\")\n",
    "    ingest_study_medication_uses_medication_relationships(driver, rels.get(\"StudyMedicationUsesMedication\"))\n",
    "    ingest_study_population_has_medical_condition_relationships(driver, rels.get(\"StudyPopulationHasMedicalCondition\"))\n",
    "    ingest_study_population_receives_study_medication_relationships(driver, rels.get(\"StudyPopulationReceivesStudyMedication\"))\n",
    "    ingest_study_population_has_clinical_outcome_relationships(driver, rels.get(\"StudyPopulationHasClinicalOutcome\"))\n",
    "    ingest_study_medication_produces_clinical_outcome_relationships(driver, rels.get(\"StudyMedicationProducesClinicalOutcome\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingest_records = prepare_entities_for_ingestion(entity_ingest_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingesting Nodes\n",
      "Linking Nodes to Chunks\n",
      "Ingesting Relationships\n"
     ]
    }
   ],
   "source": [
    "ingest_entities(driver, ingest_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
