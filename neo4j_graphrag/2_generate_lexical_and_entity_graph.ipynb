{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PubMed Knowledge Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is part of a series that walks through the process of generating a knowledge graph of PubMed articles.\n",
    "\n",
    "It will use the Neo4j GraphRAG Python Package to create a pipeline that parses documents, extracts entities and loads data into Neo4j. \n",
    "\n",
    "This notebook is based on the custom pipeline example provided by the [Neo4j GraphRAG Python Package documentation](https://github.com/neo4j/neo4j-graphrag-python/blob/main/examples/customize/build_graph/pipeline/kg_builder_from_pdf.py).\n",
    "\n",
    "**Please see the [Neo4j GraphRAG Section README](./README.md) for details on differences from the main notebooks and known bugs.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allows for async operations in notebooks\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "from typing import Any\n",
    "\n",
    "from neo4j_graphrag.experimental.components.entity_relation_extractor import (\n",
    "    LLMEntityRelationExtractor,\n",
    "    OnError,\n",
    ")\n",
    "from neo4j_graphrag.experimental.components.kg_writer import Neo4jWriter\n",
    "from neo4j_graphrag.experimental.components.pdf_loader import PdfLoader\n",
    "from neo4j_graphrag.experimental.components.resolver import (\n",
    "    FuzzyMatchResolver,\n",
    ")\n",
    "from neo4j_graphrag.experimental.components.schema import (\n",
    "    SchemaBuilder,\n",
    "    NodeType,\n",
    "    RelationshipType,\n",
    "    PropertyType,\n",
    ")\n",
    "from neo4j_graphrag.experimental.components.text_splitters.fixed_size_splitter import (\n",
    "    FixedSizeSplitter,\n",
    ")\n",
    "from neo4j_graphrag.llm import LLMInterface, OpenAILLM\n",
    "\n",
    "from neo4j_graphrag.experimental.pipeline import Pipeline\n",
    "\n",
    "from neo4j import Driver, GraphDatabase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity Graph Schema Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the entities and relationships to extract from the documents. \n",
    "\n",
    "These are the same as the entities and relationships that are defined in `3_generate_entity_graph.ipynb`, however here we are using the Neo4j GraphRAG classes `NodeType`, `RelationshipType` and `PropertyType` instead of defining our own Pydantic classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is what our entity graph data model looks like.\n",
    "\n",
    "<img src=\"../assets/images/entity-data-model.png\" alt=\"entity-data-model\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Node Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "medication = NodeType(\n",
    "    label=\"Medication\",\n",
    "    description=\"A substance used for medical treatment - a medicine or drug. This is a general representation of a medication. A Medication node may have relationships to TreatmentArm nodes that are specific to a particular study.\",\n",
    "    properties=[\n",
    "        PropertyType(name=\"name\", type=\"STRING\", required=True, description=\"Name of the medication. Should also be uniquely identifiable. Do not include dosage, administration, frequency, or other details.\"),\n",
    "        PropertyType(name=\"medicationClass\", type=\"STRING\", required=True, description=\"Drug class (e.g., GLP-1 RA, SGLT2i)\"),\n",
    "        PropertyType(name=\"mechanism\", type=\"STRING\", description=\"Mechanism of action\"),\n",
    "        PropertyType(name=\"genericName\", type=\"STRING\", description=\"Generic name of the medication\"),\n",
    "        PropertyType(name=\"brandNames\", type=\"LIST\", description=\"Commercial brand names\"),\n",
    "        PropertyType(name=\"approvalStatus\", type=\"STRING\", description=\"FDA approval status\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "treatment_arm = NodeType(\n",
    "    label=\"TreatmentArm\",\n",
    "    description=\"A treatment arm is a group of participants who receive the same treatment. It may be a control arm or an experimental arm.\",\n",
    "    properties=[\n",
    "        PropertyType(name=\"id\", type=\"STRING\", required=True, description=\"The unique id of the treatment arm. This is a combination of the study name and treatment arm name. Follows the pattern: <study_name>_<treatment_arm_name>\"),\n",
    "        PropertyType(name=\"studyName\", type=\"STRING\", required=True, description=\"Name of the study. This is used to uniquely identify the TreatmentArm node.\"),\n",
    "        PropertyType(name=\"name\", type=\"STRING\", required=True, description=\"Name of the treatment arm\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "clinical_outcome = NodeType(\n",
    "    label=\"ClinicalOutcome\",\n",
    "    description=\"A clinical outcome of a treatment arm. This describes the resulting effect a treatment has on a treatment arm population.\",\n",
    "    properties=[\n",
    "        PropertyType(name=\"id\", type=\"STRING\", required=True, description=\"The unique id of the clinical outcome. This is a combination of the study name and the name of the outcome. Follows the pattern: <study_name>_<outcome_name>\"),\n",
    "        PropertyType(name=\"studyName\", type=\"STRING\", required=True, description=\"Name of the study this outcome is associated with. This is used to uniquely identify the ClinicalOutcome node.\"),\n",
    "        PropertyType(name=\"name\", type=\"STRING\", required=True, description=\"Name of the clinical outcome.\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "medical_condition = NodeType(\n",
    "    label=\"MedicalCondition\",\n",
    "    description=\"Medical conditions and comorbidities studied\",\n",
    "    properties=[\n",
    "        PropertyType(name=\"name\", type=\"STRING\", required=True, description=\"Name of the medical condition\"),\n",
    "        PropertyType(name=\"category\", type=\"STRING\", required=True, description=\"Category of condition\"),\n",
    "        PropertyType(name=\"icd10Code\", type=\"STRING\", description=\"ICD-10 code when available\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "study_population = NodeType(\n",
    "    label=\"StudyPopulation\",\n",
    "    description=\"Patient populations and demographics in research studies\",\n",
    "    properties=[\n",
    "        PropertyType(name=\"id\", type=\"STRING\", required=True, description=\"The unique id of the study population. This is a combination of the study name and the population description. Follows the pattern: <study_name>_<population_description>\"),\n",
    "        PropertyType(name=\"studyName\", type=\"STRING\", required=True, description=\"Name of the study. This is used to uniquely identify the StudyPopulation node.\"),\n",
    "        PropertyType(name=\"description\", type=\"STRING\", required=True, description=\"Description of the population\"),\n",
    "        PropertyType(name=\"minAge\", type=\"INTEGER\", description=\"Minimum age in years\"),\n",
    "        PropertyType(name=\"maxAge\", type=\"INTEGER\", description=\"Maximum age in years\"),\n",
    "        PropertyType(name=\"malePercentage\", type=\"FLOAT\", description=\"Percentage of male gender participants\"),\n",
    "        PropertyType(name=\"femalePercentage\", type=\"FLOAT\", description=\"Percentage of female gender participants\"),\n",
    "        PropertyType(name=\"otherGenderPercentage\", type=\"FLOAT\", description=\"Percentage of participants that identify as another gender\"),\n",
    "        PropertyType(name=\"sampleSize\", type=\"INTEGER\", description=\"Number of participants\"),\n",
    "        PropertyType(name=\"studyType\", type=\"STRING\", required=True, description=\"Type of study\"),\n",
    "        PropertyType(name=\"inclusionCriteria\", type=\"LIST\", description=\"Key inclusion criteria\"),\n",
    "        PropertyType(name=\"exclusionCriteria\", type=\"LIST\", description=\"Key exclusion criteria\"),\n",
    "        PropertyType(name=\"studyDuration\", type=\"STRING\", description=\"Duration of study\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "nodes = [medication, treatment_arm, clinical_outcome, medical_condition, study_population]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relationship Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the Relationship types that will be extracted from the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "medication_used_in_treatment_arm = RelationshipType(\n",
    "    label=\"USED_IN_TREATMENT_ARM\",\n",
    "    description=\"Study-specific medication usage - how a Medication was used in a particular TreatmentArm. This describes an instance of a medication that is used in a particular treatment arm. All treatment arms should have a relationship with at least one Medication node.\",\n",
    "    properties=[\n",
    "        PropertyType(name=\"dosage\", type=\"STRING\", description=\"Dosage used in this study\"),\n",
    "        PropertyType(name=\"route\", type=\"STRING\", description=\"Route of administration\"),\n",
    "        PropertyType(name=\"frequency\", type=\"STRING\", description=\"Dosing frequency\"),\n",
    "        PropertyType(name=\"treatment_duration\", type=\"STRING\", description=\"Duration of treatment\"),\n",
    "        PropertyType(name=\"comparator\", type=\"STRING\", description=\"What this was compared against\"),\n",
    "        PropertyType(name=\"adherence_rate\", type=\"FLOAT\", description=\"Treatment adherence rate\"),\n",
    "        PropertyType(name=\"formulation\", type=\"STRING\", description=\"Specific formulation used\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "treatment_arm_has_clinical_outcome = RelationshipType(\n",
    "    label=\"HAS_CLINICAL_OUTCOME\",\n",
    "    description=\"Links TreatmentArm to ClinicalOutcome nodes. TreatmentArm nodes should have a relationship with a ClinicalOutcome node.\",\n",
    ")\n",
    "\n",
    "study_population_has_medical_condition = RelationshipType(\n",
    "    label=\"HAS_MEDICAL_CONDITION\",\n",
    "    description=\"Links StudyPopulation to MedicalCondition nodes. StudyPopulation nodes should have a relationship with a MedicalCondition node.\",\n",
    "   \n",
    ")\n",
    "\n",
    "study_population_in_treatment_arm = RelationshipType(\n",
    "    label=\"IN_TREATMENT_ARM\",\n",
    "    description=\"Links StudyPopulation to TreatmentArm nodes. StudyPopulation nodes should have a relationship with a TreatmentArm node.\",\n",
    "   \n",
    ")\n",
    "\n",
    "relationships = [medication_used_in_treatment_arm, \n",
    "                 treatment_arm_has_clinical_outcome, \n",
    "                 study_population_has_medical_condition, \n",
    "                 study_population_in_treatment_arm]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here we must define the explicit patterns that exist in our entity graph. \n",
    "\n",
    "These are triples of `(source, relationship, target)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = [\n",
    "    (\"Medication\", \"USED_IN_TREATMENT_ARM\", \"TreatmentArm\"),\n",
    "    (\"TreatmentArm\", \"HAS_CLINICAL_OUTCOME\", \"ClinicalOutcome\"),\n",
    "    (\"StudyPopulation\", \"HAS_MEDICAL_CONDITION\", \"MedicalCondition\"),\n",
    "    (\"StudyPopulation\", \"IN_TREATMENT_ARM\", \"TreatmentArm\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now can create a pipeline to read our PDF documents, extract entities and load the data into Neo4j."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our processing pipeline will flow like this:\n",
    "\n",
    "**PDF Loader &rarr; Text Splitter &rarr; Entity Extraction &rarr; Neo4j Writer &rarr; Entity Resolver**\n",
    "\n",
    "**&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Schema Builder &nearr;**\n",
    "\n",
    "\n",
    "Where\n",
    "* **PDF Loader** &rarr; Loads the PDF into a text format\n",
    "* **Text Splitter** &rarr; Chunks text according to configuration\n",
    "* **Schema Builder** &rarr; Create entity schema according to the nodes, relationships and patterns defined above\n",
    "* **Entity Extraction** &rarr; Extract entities and relationships from the text chunks according to the defined schema\n",
    "* **Neo4j Writer** &rarr; Ingests lexical and entity graphs\n",
    "* **Entity Resolver** &rarr; Resolves `Medication` nodes according to the `name` property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline(llm: LLMInterface, neo4j_driver: Driver) -> Pipeline:\n",
    "    \"\"\"\n",
    "    Create a pipeline for generating a knowledge graph from a PDF file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    llm : LLMInterface\n",
    "        The LLM to use for the pipeline.\n",
    "    neo4j_driver : neo4j.Driver\n",
    "        The Neo4j driver to use for the pipeline.\n",
    "    nodes : list[NodeType]\n",
    "        The list of nodes to use for the pipeline.\n",
    "    relationships : list[RelationshipType]\n",
    "        The list of relationships to use for the pipeline.\n",
    "    patterns : list[Tuple[str, str, str]]\n",
    "        The list of patterns to use for the pipeline.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Pipeline\n",
    "        The pipeline for generating a knowledge graph from a PDF file.\n",
    "    \"\"\"\n",
    "\n",
    "    pipe = Pipeline()\n",
    "\n",
    "    # PdfLoader will load the PDF file into a string.\n",
    "    pipe.add_component(PdfLoader(), \"pdf_loader\")\n",
    "\n",
    "    # FixedSizeSplitter will split the text into chunks of 1000 characters with 200 character overlap.\n",
    "    pipe.add_component(\n",
    "        FixedSizeSplitter(chunk_size=1000, chunk_overlap=200, approximate=False),\n",
    "        \"splitter\",\n",
    "    )\n",
    "\n",
    "    # SchemaBuilder will build the schema for the graph based on the input nodes and relationships.\n",
    "    pipe.add_component(SchemaBuilder(), \"schema\")\n",
    "\n",
    "    # LLMEntityRelationExtractor will extract the entities and relationships from the text.\n",
    "    pipe.add_component(\n",
    "        LLMEntityRelationExtractor(\n",
    "            llm=llm,\n",
    "            on_error=OnError.RAISE,\n",
    "        ),\n",
    "        \"extractor\",\n",
    "    )\n",
    "\n",
    "    # Neo4jWriter will write the graph to the Neo4j database.\n",
    "    pipe.add_component(Neo4jWriter(neo4j_driver), \"writer\")\n",
    "\n",
    "    # FuzzyMatchResolver will resolve our Medication nodes based on their name, generic name, and brand names.\n",
    "    pipe.add_component(FuzzyMatchResolver(neo4j_driver, \n",
    "                                          filter_query=\"WHERE entity:Medication\",\n",
    "                                          resolve_properties=[\"name\"]), \"medication_resolver\")\n",
    "    \n",
    "    # Connect the components together.\n",
    "    pipe.connect(\"pdf_loader\", \"splitter\", input_config={\"text\": \"pdf_loader.text\"})\n",
    "    pipe.connect(\"splitter\", \"extractor\", input_config={\"chunks\": \"splitter\"})\n",
    "    pipe.connect(\n",
    "        \"schema\",\n",
    "        \"extractor\",\n",
    "        input_config={\n",
    "            \"schema\": \"schema\",\n",
    "            \"document_info\": \"pdf_loader.document_info\",\n",
    "        },\n",
    "    )\n",
    "    pipe.connect(\n",
    "        \"extractor\",\n",
    "        \"writer\",\n",
    "        input_config={\"graph\": \"extractor\"},\n",
    "    )\n",
    "    pipe.connect(\"writer\", \"medication_resolver\")\n",
    "\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our inputs need to be properly formatted, so we create the function below to ensure we are passing the appropriate input object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline_input(file_path: str, \n",
    "                          nodes: list[NodeType], \n",
    "                          relationships: list[RelationshipType], \n",
    "                          patterns: list[tuple[str, str, str]]) -> dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Create an input for the pipeline.\n",
    "    This will create a single input to be fed to the knowledge graph generation pipeline.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : str\n",
    "        The path to the PDF file to load.\n",
    "    nodes : list[NodeType]\n",
    "        The list of nodes to use for the pipeline.\n",
    "    relationships : list[RelationshipType]\n",
    "        The list of relationships to use for the pipeline.\n",
    "    patterns : list[tuple[str, str, str]]\n",
    "        The list of patterns to use for the pipeline.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict[str, Any]\n",
    "        The input for the pipeline.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"pdf_loader\": {\n",
    "            \"filepath\": file_path,\n",
    "        },\n",
    "        \"schema\": {\n",
    "            \"node_types\": nodes,\n",
    "            \"relationship_types\": relationships,\n",
    "            \"patterns\": patterns,\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using OpenAI GPT-4o for our entity extraction process.\n",
    "\n",
    "Note that we are using the Neo4j GraphRAG Python Package client wrapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAILLM(\n",
    "        model_name=\"gpt-4o\",\n",
    "        model_params={\n",
    "            \"response_format\": {\"type\": \"json_object\"},\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create our Neo4j driver instance..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "neo4j_driver = GraphDatabase.driver(os.getenv(\"NEO4J_URI\"), \n",
    "                                    auth=(os.getenv(\"NEO4J_USERNAME\"), os.getenv(\"NEO4J_PASSWORD\")),\n",
    "                                    database=os.getenv(\"NEO4J_DATABASE\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and initialize our pipeline defined above with the OpenAI client and Neo4j driver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = create_pipeline(llm, neo4j_driver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running our pipeline, we need to collect the PDFs we'd like to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found PDFs\n",
      "*  nihms-1852972.pdf\n",
      "*  fendo-11-00178.pdf\n",
      "*  Diabetic Medicine - 2023 - Brønden - Effects of DPP‐4 inhibitors  GLP‐1 receptor agonists  SGLT‐2 inhibitors and.pdf\n",
      "*  jama_rosenstock_2019_oi_190026_1655321720.77793.pdf\n",
      "*  jciinsight-3-93936.pdf\n"
     ]
    }
   ],
   "source": [
    "PDF_DIR = \"../articles/pdf/\"\n",
    "\n",
    "pdf_files = [f for f in os.listdir(PDF_DIR) if f.endswith(\".pdf\")]\n",
    "\n",
    "print(\"Found PDFs\")\n",
    "for pdf in pdf_files:\n",
    "    print(\"* \", pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_pipeline_for_many_pdfs(pipeline: Pipeline, pdf_directory: str, pdf_files: list[str]) -> list[str]:\n",
    "    \"\"\"\n",
    "    Run a collection of PDFs through the provided pipeline.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pipeline : Pipeline\n",
    "        The pipeline to run the PDFs through.\n",
    "    pdf_directory : str\n",
    "        The directory containing the PDFs.\n",
    "    pdf_files : list[str]\n",
    "        The list of PDF file names to run through the pipeline.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[str]\n",
    "        The list of PDF file names that failed to be processed.\n",
    "    \"\"\"\n",
    "\n",
    "    failed_cache: list[str] = list()\n",
    "\n",
    "    async for i, pdf_file in enumerate(pdf_files):\n",
    "        print(f\"Processing PDF {i + 1}/{len(pdf_files)}: {pdf_file}\")\n",
    "        try:\n",
    "            pdf_path = os.path.join(pdf_directory, pdf_file)\n",
    "            pipeline_input = create_pipeline_input(pdf_path, nodes, relationships, patterns)\n",
    "            await pipeline.run(pipeline_input)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing PDF {pdf_file}: {e}\")\n",
    "            failed_cache.append(pdf_file)\n",
    "            continue\n",
    "\n",
    "    return failed_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've defined the PDF files we'd like to load, we can run the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing PDF 1/2: nihms-1852972.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiple definitions in dictionary at byte 0x2d4a7 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x2d6e8 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x2d8d2 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x2da94 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x2dc2e for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x2de38 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x2e01a for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x2e204 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x2e41e for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x2e630 for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x2e8aa for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x2eafc for key /MediaBox\n",
      "Multiple definitions in dictionary at byte 0x2ed5e for key /MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing PDF 2/2: fendo-11-00178.pdf\n"
     ]
    }
   ],
   "source": [
    "failed_pdfs = asyncio.run(run_pipeline_for_many_pdfs(pipeline, PDF_DIR, pdf_files[:2]))\n",
    "\n",
    "# Basic retry logic for failed PDFs\n",
    "# Here we retry a document only once\n",
    "if len(failed_pdfs) > 0:\n",
    "    print(f\"Failed to process {len(failed_pdfs)} PDFs: {failed_pdfs}\")\n",
    "    print(\"Retrying failed PDFs...\")\n",
    "    failed_pdfs = asyncio.run(run_pipeline_for_many_pdfs(pipeline, PDF_DIR, failed_pdfs))\n",
    "    print(f\"Failed to process {len(failed_pdfs)} PDFs: {failed_pdfs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we should close our driver and client connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neo4j_driver.close()\n",
    "await llm.async_client.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
