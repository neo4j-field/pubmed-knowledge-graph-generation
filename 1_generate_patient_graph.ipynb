{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PubMed Knowledge Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is part of a series that walks through the process of generating a knowledge graph of PubMed articles.\n",
    "\n",
    "This notebook will\n",
    "* Load structured patient journey data into a Neo4j instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from pyneoinstance import Neo4jInstance, load_yaml_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyNeoInstance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our database credentials and all of our queries are stored in the `pyneoinstance_config.yaml` file. \n",
    "\n",
    "This makes it easy to manage our queries and keeps the notebook code clean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_yaml_file(\"pyneoinstance_config.yaml\")\n",
    "\n",
    "db_info = config['db_info']\n",
    "\n",
    "constraints = config['initializing_queries']['constraints']\n",
    "indexes = config['initializing_queries']['indexes']\n",
    "\n",
    "load_queries = config['patient_journey']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph object will handle database connections and read / write transactions for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Neo4jInstance(db_info.get('uri', os.getenv(\"NEO4J_URI\", \"neo4j://localhost:7687\")), # use config value -> use env value -> use default value\n",
    "                      db_info.get('user', os.getenv(\"NEO4J_USER\", \"neo4j\")), \n",
    "                      db_info.get('password', os.getenv(\"NEO4J_PASSWORD\", \"password\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a helper function for ingesting data using the PyNeoInstance library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_partition(data: pd.DataFrame, batch_size: int = 500) -> int:\n",
    "    \"\"\"\n",
    "    Determine the data partition based on the desired batch size.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        The Pandas DataFrame to partition.\n",
    "    batch_size : int\n",
    "        The desired batch size.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        The partition size.\n",
    "    \"\"\"\n",
    "    \n",
    "    partition = int(len(data) / batch_size)\n",
    "    print(\"partition: \"+str(partition if partition > 1 else 1))\n",
    "    return partition if partition > 1 else 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constraints + Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_constraints_and_indexes() -> None:\n",
    "    \"\"\"\n",
    "    Create constraints and indexes for the lexical and domain graphs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if constraints and len(constraints) > 0:\n",
    "            graph.execute_write_queries(database=db_info['database'], queries=list(constraints.values()))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    try:\n",
    "        if indexes and len(indexes) > 0:\n",
    "            graph.execute_write_queries(database=db_info['database'], queries=list(indexes.values()))\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_constraints_and_indexes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our patient journey data will be loaded from a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_patient_journey_data(graph: Neo4jInstance, dataframe_tuples: list[tuple[str, pd.DataFrame]]) -> None:\n",
    "    \"\"\"\n",
    "    Load patient journey data into the graph.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    graph: Neo4jInstance\n",
    "        The graph to load the data into.\n",
    "    dataframe_tuples: list[tuple[str, pd.DataFrame]]\n",
    "        A list of tuples, where the first element is the name of the query in the config and the second element is the associated dataframe.\n",
    "    \"\"\"\n",
    "\n",
    "    for query_name, dataframe in dataframe_tuples:\n",
    "        print(f\"Loading {len(dataframe)} {query_name} rows\")\n",
    "        res = graph.execute_write_query_with_data(database=db_info['database'], \n",
    "                                                data=dataframe, \n",
    "                                                query=load_queries[query_name], \n",
    "                                                partitions=get_partition(dataframe, batch_size=500),\n",
    "                                                parallel=False)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/patient_journey\"\n",
    "data_tuples = [\n",
    "    (\"patients\", pd.read_csv(f\"{data_path}/patients.csv\")),\n",
    "    (\"providers\", pd.read_csv(f\"{data_path}/providers.csv\")),\n",
    "    (\"claims\", pd.read_csv(f\"{data_path}/claims_with_all_codes.csv\")),\n",
    "    (\"events\", pd.read_csv(f\"{data_path}/patient_journey_with_providers.csv\")),\n",
    "    (\"conditions\", pd.read_csv(f\"{data_path}/conditions.csv\")),\n",
    "    (\"care_gaps\", pd.read_csv(f\"{data_path}/care_gaps.csv\")),\n",
    "    (\"risk_scores\", pd.read_csv(f\"{data_path}/risk_scores.csv\"))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we load our patient journey data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 221 patient journey rows\n",
      "partition: 1\n",
      "{'labels_added': 139, 'relationships_created': 863, 'nodes_created': 139, 'properties_set': 938}\n"
     ]
    }
   ],
   "source": [
    "load_patient_journey_data(graph, data_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
