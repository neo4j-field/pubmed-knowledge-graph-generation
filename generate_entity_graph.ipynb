{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PubMed Knowledge Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is part of a series that walks through the process of generating a knowledge graph of PubMed articles.\n",
    "\n",
    "This notebook will\n",
    "* Extract entities from the Chunk nodes in a Neo4j graph according to the defined schema\n",
    "* Load the entities and connect them with their respective Chunk nodes\n",
    "* Connect the entities as defined by the Domain Graph Data Model\n",
    "* Connect extracted entities with existing patient journey graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter some Numpy warnings that pop up during ingestion\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import hashlib\n",
    "from typing import Any, Optional, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allows for async operations in notebooks\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pydantic import BaseModel, Field, computed_field, field_validator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain Graph Schema Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to define our knowledge graph schema. This information will be passed to the entity extraction LLM to control which entities and relationships are pulled out of the text.\n",
    "\n",
    "This is necessary to prevent our schema from growing too large with an unbounded extraction process.\n",
    "\n",
    "We are using Pydantic to define the schema here since it can be used to validate any returned results as well. This ensures that all data we are ingesting into Neo4j adheres to this structure.\n",
    "\n",
    "Here is what our domain graph data model looks like.\n",
    "\n",
    "<img src=\"./assets/images/domain-data-model-v1.png\" alt=\"domain-data-model\" width=\"600px\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------\n",
    "# Nodes\n",
    "# -------------\n",
    "\n",
    "class Medication(BaseModel):\n",
    "    \"\"\"\n",
    "    A substance used for medical treatment - a medicine or drug. \n",
    "    This is a general representation of a medication. \n",
    "    A Medication node may have relationships to TreatmentArm nodes that are specific to a particular study.\n",
    "    \"\"\"\n",
    "    \n",
    "    name: str = Field(..., description=\"Name of the medication. Should also be uniquely identifiable. Do not include dosage, administration, frequency, or other details.\")\n",
    "    medication_class: str = Field(..., description=\"Drug class (e.g., GLP-1 RA, SGLT2i)\")\n",
    "    mechanism: Optional[str] = Field(None, description=\"Mechanism of action\")\n",
    "    generic_name: Optional[str] = Field(None, description=\"Generic name of the medication\")\n",
    "    brand_names: Optional[List[str]] = Field(None, description=\"Commercial brand names\")\n",
    "    approval_status: Optional[str] = Field(None, description=\"FDA approval status\")\n",
    "    \n",
    "    class Config:\n",
    "        json_schema_extra = {\n",
    "            \"examples\": [\n",
    "                {\n",
    "                    \"name\": \"semaglutide\", \n",
    "                    \"medication_class\": \"GLP-1 receptor agonist\",\n",
    "                    \"mechanism\": \"GLP-1 receptor activation\",\n",
    "                    \"generic_name\": \"semaglutide\",\n",
    "                    \"brand_names\": [\"ozempic\", \"wegovy\", \"rybelsus\"],\n",
    "                    \"approval_status\": \"FDA approved\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    @field_validator(\"name\", \"medication_class\")\n",
    "    def validate_lower_case(cls, v: str) -> str:\n",
    "        \"\"\"\n",
    "        Validate that the field value is all lower case.\n",
    "        \"\"\"\n",
    "        return v.lower()\n",
    "    \n",
    "    @field_validator(\"generic_name\")\n",
    "    def validate_generic_name(cls, v: str | None) -> str | None:\n",
    "        \"\"\"\n",
    "        Validate that the generic name is all lower case.\n",
    "        \"\"\"\n",
    "        if v is not None:\n",
    "            return v.lower()\n",
    "        return v\n",
    "    \n",
    "    @field_validator(\"brand_names\")\n",
    "    def validate_brand_names(cls, v: list[str] | None) -> list[str] | None:\n",
    "        \"\"\"\n",
    "        Validate that the brand names are all lower case.\n",
    "        \"\"\"\n",
    "        if v is not None:\n",
    "            return [name.lower() for name in v]\n",
    "        return v\n",
    "\n",
    "\n",
    "class TreatmentArm(BaseModel):\n",
    "    \"\"\"\n",
    "    A treatment arm is an explicit instance of a participant group in a study that receive the same treatment.\n",
    "    A treatment arm should have relationships to Medication and ClinicalOutcome nodes.\n",
    "    \"\"\"\n",
    "    study_name: str = Field(..., description=\"Name of the study. This is used to uniquely identify the TreatmentArm node.\")\n",
    "    name: str = Field(..., description=\"Name of the treatment arm\")\n",
    "\n",
    "    class Config:\n",
    "        json_schema_extra = {\n",
    "            \"examples\": [\n",
    "                {\n",
    "                    \"study_name\": \"Study 1\",\n",
    "                    \"name\": \"Treatment arm 1\",\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    @computed_field(return_type=str)\n",
    "    def treatment_arm_id(self) -> str:\n",
    "        \"\"\"\n",
    "        The unique id of the treatment arm.\n",
    "        This is a sha256 hash of the study name and treatment arm name.\n",
    "        \"\"\"\n",
    "        return hashlib.sha256(f\"{self.study_name}_{self.name}\".encode()).hexdigest()\n",
    "    \n",
    "\n",
    "class ClinicalOutcome(BaseModel):\n",
    "    \"\"\"\n",
    "    Measured clinical outcomes and biomarkers.\n",
    "    This node represents a clinical outcome present in a study.\n",
    "    ClinicalOutcome nodes should have relationships with other entity nodes from a study.\n",
    "    ClinicalOutcome nodes should not have relationships with entities that exist outside the study.\n",
    "    \"\"\"\n",
    "    \n",
    "    study_name: str = Field(..., description=\"Name of the study this outcome is associated with. This is used to uniquely identify the ClinicalOutcome node.\")\n",
    "    name: str = Field(..., description=\"A concise detailed name for the outcome.\")\n",
    "\n",
    "    @computed_field(return_type=str)\n",
    "    def clinical_outcome_id(self) -> str:\n",
    "        \"\"\"\n",
    "        The unique id of the clinical outcome.\n",
    "        This is a sha256 hash of the study name and the name of the outcome.\n",
    "        \"\"\"\n",
    "        return hashlib.sha256(f\"{self.study_name}_{self.name}\".encode()).hexdigest()\n",
    "    \n",
    "    class Config:\n",
    "        json_schema_extra = {\n",
    "            \"examples\": [\n",
    "                # don't include the clinical_outcome_id in the example since this is computed from extracted fields\n",
    "                {\n",
    "                    \"study_name\": \"Study 1\",\n",
    "                    \"name\": \"A1C controlled\",\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "\n",
    "class MedicalCondition(BaseModel):\n",
    "    \"\"\"Medical conditions and comorbidities studied\"\"\"\n",
    "    \n",
    "    name: str = Field(..., description=\"Name of the medical condition\")\n",
    "    category: str = Field(..., description=\"Category of condition\")\n",
    "    icd10_code: Optional[str] = Field(None, description=\"ICD-10 code when available\")\n",
    "    \n",
    "    @field_validator(\"icd10_code\")\n",
    "    def validate_icd10_code(cls, v: str) -> str:\n",
    "        \"\"\"\n",
    "        Validate that the ICD-10 code is valid.\n",
    "        \"\"\"\n",
    "        # ICD-10 codes are 3-7 characters long\n",
    "        if len(v) < 3 or len(v) > 7:\n",
    "            raise ValueError(\"ICD-10 code must be between 3 and 7 characters long.\")\n",
    "        # first character must be a letter\n",
    "        elif not v[0].isalpha():\n",
    "            raise ValueError(\"ICD-10 code must start with a letter.\")\n",
    "        # first character not case sensitive, can't be U, O, or I\n",
    "        elif v[0].upper() in [\"U\", \"O\", \"I\"]:\n",
    "            raise ValueError(\"ICD-10 code can not start with 'U', 'O', or 'I'.\")\n",
    "        # second character must be a digit\n",
    "        elif not v[1].isdigit():\n",
    "            raise ValueError(\"ICD-10 code second character must be a digit.\")\n",
    "        # '.' must separate the first 3 characters from the rest of the code\n",
    "        # examples:\n",
    "        # S52 Fracture of forearm\n",
    "        # S52.5 Fracture of lower end of radius\n",
    "        # S52.52 Torus fracture of lower end of radius\n",
    "        # S52.521 Torus fracture of lower end of right radius\n",
    "        # S52.521A Torus fracture of lower end of right radius, initial encounter, closed fracture\n",
    "        elif len(v) > 3 and not v[3] == '.':\n",
    "            raise ValueError(\"ICD-10 code must have a '.' after the first 3 characters.\")\n",
    "        return v\n",
    "    \n",
    "    class Config:\n",
    "        json_schema_extra = {\n",
    "            \"examples\": [\n",
    "                {\n",
    "                    \"name\": \"Type 2 diabetes mellitus\",\n",
    "                    \"category\": \"diabetes\",\n",
    "                    \"icd10_code\": \"E11\",\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "\n",
    "class StudyPopulation(BaseModel):\n",
    "    \"\"\"Patient populations and demographics in research studies\"\"\"\n",
    "    \n",
    "    study_name: str = Field(..., description=\"Name of the study. This is used to uniquely identify the StudyPopulation node.\")\n",
    "    description: str = Field(..., description=\"Description of the population\")\n",
    "    min_age: Optional[int] = Field(None, description=\"Minimum age in years\")\n",
    "    max_age: Optional[int] = Field(None, description=\"Maximum age in years\")\n",
    "    male_percentage: Optional[float] = Field(None, description=\"Percentage of male gender participants\")\n",
    "    female_percentage: Optional[float] = Field(None, description=\"Percentage of female gender participants\")\n",
    "    other_gender_percentage: Optional[float] = Field(None, description=\"Percentage of participants that identify as another gender\")\n",
    "    sample_size: Optional[int] = Field(None, description=\"Number of participants\")\n",
    "    study_type: str = Field(..., description=\"Type of study\")\n",
    "    location: Optional[str] = Field(None, description=\"Geographic location of study\")\n",
    "    inclusion_criteria: Optional[List[str]] = Field(None, description=\"Key inclusion criteria\")\n",
    "    exclusion_criteria: Optional[List[str]] = Field(None, description=\"Key exclusion criteria\")\n",
    "    study_duration: Optional[str] = Field(None, description=\"Duration of study\")\n",
    "    \n",
    "    class Config:\n",
    "        json_schema_extra = {\n",
    "            \"examples\": [\n",
    "                {\n",
    "                    \"study_name\": \"Study 1\",\n",
    "                    \"description\": \"Adults with T2DM and schizophrenia\",\n",
    "                    \"min_age\": 30,\n",
    "                    \"max_age\": 39,\n",
    "                    \"male_percentage\": 46.0,\n",
    "                    \"female_percentage\": 53.0,\n",
    "                    \"other_gender_percentage\": 1.0,\n",
    "                    \"sample_size\": 100,\n",
    "                    \"study_type\": \"Observational study\",\n",
    "                    \"location\": \"Denmark\",\n",
    "                    \"inclusion_criteria\": [\"Type 2 diabetes diagnosis\", \"Schizophrenia diagnosis\", \"Age ≥18\"],\n",
    "                    \"study_duration\": \"12 months\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    @computed_field(return_type=str)\n",
    "    def study_population_id(self) -> str:\n",
    "        \"\"\"\n",
    "        The unique id of the study population.\n",
    "        This is a sha256 hash of the study name.\n",
    "        \"\"\"\n",
    "        return hashlib.sha256(f\"{self.study_name}_{self.description}\".encode()).hexdigest()\n",
    "\n",
    "\n",
    "# -------------\n",
    "# Relationships\n",
    "# -------------\n",
    "\n",
    "class MedicationUsedInTreatmentArm(BaseModel):\n",
    "    \"\"\"\n",
    "    Study-specific medication usage - how a Medication was used in a particular TreatmentArm.\n",
    "    This describes an instance of a medication that is used in a particular treatment arm. \n",
    "    All treatment arms should have a relationship with at least one Medication node.\n",
    "    \"\"\"\n",
    "    study_name: str = Field(..., description=\"Name of the study.\")\n",
    "    treatment_arm_name: str = Field(..., description=\"Name of the treatment arm.\")\n",
    "    medication_name: str = Field(..., description=\"Name of the medication.\")\n",
    "    dosage: Optional[str] = Field(None, description=\"Dosage used in this study\")\n",
    "    route: Optional[str] = Field(None, description=\"Route of administration\")\n",
    "    frequency: Optional[str] = Field(None, description=\"Dosing frequency\")\n",
    "    treatment_duration: Optional[str] = Field(None, description=\"Duration of treatment\")\n",
    "    comparator: Optional[str] = Field(None, description=\"What this was compared against\")\n",
    "    adherence_rate: Optional[float] = Field(None, description=\"Treatment adherence rate\")\n",
    "    formulation: Optional[str] = Field(None, description=\"Specific formulation used\")\n",
    "\n",
    "    @computed_field(return_type=str)\n",
    "    def treatment_arm_id(self) -> str:\n",
    "        \"\"\"\n",
    "        The unique id of the treatment arm.\n",
    "        This is a sha256 hash of the study name and treatment arm.\n",
    "        \"\"\"\n",
    "        return hashlib.sha256(f\"{self.study_name}_{self.treatment_arm_name}\".encode()).hexdigest()\n",
    "    \n",
    "    @field_validator(\"medication_name\")\n",
    "    def validate_medication_name(cls, v: str) -> str:\n",
    "        \"\"\"\n",
    "        Validate that the medication name is all lower case.\n",
    "        \"\"\"\n",
    "        return v.lower()\n",
    "    \n",
    "    class Config:\n",
    "        json_schema_extra = {\n",
    "            # don't include the study_medication_id in the example since this is computed from extracted fields\n",
    "            \"examples\": [\n",
    "                {\n",
    "                    \"study_name\": \"Study 1\",\n",
    "                    \"treatment_arm_name\": \"Treatment arm 1\",\n",
    "                    \"medication_name\": \"Medication 1\",\n",
    "                    \"dosage\": \"1.0 mg\",\n",
    "                    \"route\": \"subcutaneous\",\n",
    "                    \"frequency\": \"weekly\",\n",
    "                    \"treatment_duration\": \"12 weeks\",\n",
    "                    \"comparator\": \"placebo\",\n",
    "                    \"adherence_rate\": 85.5,\n",
    "                    \"formulation\": \"pre-filled pen\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "\n",
    "class TreatmentArmHasClinicalOutcome(BaseModel):\n",
    "    \"\"\"\n",
    "    Links TreatmentArm to ClinicalOutcome nodes.\n",
    "    TreatmentArm nodes should have a relationship with a ClinicalOutcome node.\n",
    "    Pattern: (:TreatmentArm)-[:HAS_CLINICAL_OUTCOME]->(:ClinicalOutcome)\n",
    "    \"\"\"\n",
    "    study_name: str = Field(..., description=\"Name of the study. This is used to uniquely identify the TreatmentArm node.\")\n",
    "    treatment_arm_name: str = Field(..., description=\"Name of the treatment arm.\")\n",
    "    clinical_outcome_name: str = Field(..., description=\"Name of the clinical outcome\")\n",
    "\n",
    "    @computed_field(return_type=str)\n",
    "    def clinical_outcome_id(self) -> str:\n",
    "        \"\"\"\n",
    "        The unique id of the clinical outcome.\n",
    "        This is a sha256 hash of the study name and the name of the outcome.\n",
    "        \"\"\"\n",
    "        return hashlib.sha256(f\"{self.study_name}_{self.clinical_outcome_name}\".encode()).hexdigest()\n",
    "    \n",
    "    @computed_field(return_type=str)\n",
    "    def treatment_arm_id(self) -> str:\n",
    "        \"\"\"\n",
    "        The unique id of the treatment arm.\n",
    "        This is a sha256 hash of the study name and treatment arm.\n",
    "        \"\"\"\n",
    "        return hashlib.sha256(f\"{self.study_name}_{self.treatment_arm_name}\".encode()).hexdigest()\n",
    "\n",
    "\n",
    "class StudyPopulationHasMedicalCondition(BaseModel):\n",
    "    \"\"\"\n",
    "    Links StudyPopulation to MedicalCondition nodes.\n",
    "    StudyPopulation nodes should have a relationship with a MedicalCondition node.\n",
    "    Pattern: (:StudyPopulation)-[:HAS_MEDICAL_CONDITION]->(:MedicalCondition)\n",
    "    \"\"\"\n",
    "    study_name: str = Field(..., description=\"Name of the study. This is used to uniquely identify the StudyPopulation node.\")\n",
    "    study_population_description: str = Field(..., description=\"Description of the study population.\")\n",
    "    medical_condition_name: str\n",
    "\n",
    "    @computed_field(return_type=str)\n",
    "    def study_population_id(self) -> str:\n",
    "        \"\"\"\n",
    "        The unique id of the study population.\n",
    "        This is a sha256 hash of the study name and population description.\n",
    "        \"\"\"\n",
    "        return hashlib.sha256(f\"{self.study_name}_{self.study_population_description}\".encode()).hexdigest()\n",
    "\n",
    "\n",
    "class StudyPopulationInTreatmentArm(BaseModel):\n",
    "    \"\"\"\n",
    "    Links StudyPopulation to TreatmentArm nodes.\n",
    "    StudyPopulation nodes should have a relationship with a TreatmentArm node.\n",
    "    Pattern: (:StudyPopulation)-[:IN_TREATMENT_ARM]->(:TreatmentArm)\n",
    "    \"\"\"\n",
    "    study_name: str = Field(..., description=\"Name of the study. This is used to uniquely identify the StudyPopulation node.\")\n",
    "    study_population_description: str = Field(..., description=\"Description of the study population.\")\n",
    "    treatment_arm_name: str = Field(..., description=\"Name of the treatment arm.\")\n",
    "\n",
    "    @computed_field(return_type=str)\n",
    "    def treatment_arm_id(self) -> str:\n",
    "        \"\"\"\n",
    "        The unique id of the treatment arm.\n",
    "        This is a sha256 hash of the study name and treatment arm.\n",
    "        \"\"\"\n",
    "        return hashlib.sha256(f\"{self.study_name}_{self.treatment_arm_name}\".encode()).hexdigest()\n",
    "\n",
    "    @computed_field(return_type=str)\n",
    "    def study_population_id(self) -> str:\n",
    "        \"\"\"\n",
    "        The unique id of the study population.\n",
    "        This is a sha256 hash of the study name and population description.\n",
    "        \"\"\"\n",
    "        return hashlib.sha256(f\"{self.study_name}_{self.study_population_description}\".encode()).hexdigest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lexical and domain knowledge graphs will be linked with `HAS_ENTITY` relationships between Chunk nodes and domain graph nodes.\n",
    "\n",
    "This is the combined lexical and domain graph data model.\n",
    "\n",
    "IMAGE OF DATA MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entity Extraction via LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using [OpenAI](https://platform.openai.com/docs/overview) and the [Instructor](https://python.useinstructor.com/) library to perform our entity extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AsyncOpenAI\n",
    "import instructor\n",
    "from instructor.exceptions import IncompleteOutputException, InstructorRetryException, ValidationError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructor handles requesting structured outputs from the LLM. \n",
    "\n",
    "If the LLM fails to return output that adheres to the response models, Instructor will also handle the retry logic and pass any errors to inform corrections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = instructor.from_openai(AsyncOpenAI())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the system prompt defines the overall behavior of the LLM\n",
    "system_prompt = \"\"\"You are a healthcare research expert that is responsible for extracting detailed entities from PubMed articles. \n",
    "You will be provided a graph data model schema and must extract entities and relationships to populate a knowledge graph.\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"Rules:\n",
    "* Use the provided schema to extract entities and relationships from the provided text.\n",
    "* Follow the schema desciptions strictly.\n",
    "* If a field is not provided, do not include it in the response. It should be null.\n",
    "* If no entities are found, return an empty list.\n",
    "\n",
    "Text Chunk:\n",
    "{text_chunk}\"\"\"\n",
    "\n",
    "async def extract_entities_from_text_chunk(text_chunk: str, chunk_id: str) -> list:\n",
    "    \"\"\"\n",
    "    Extract entities and relationships from a text chunk.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text_chunk : str\n",
    "        The text chunk to extract entities from.\n",
    "    chunk_id : str\n",
    "        The id of the text chunk. Used for debugging.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[\n",
    "        Medication | \n",
    "        TreatmentArm | \n",
    "        ClinicalOutcome | \n",
    "        MedicationUsedInTreatmentArm | \n",
    "        TreatmentArmHasClinicalOutcome |\n",
    "        StudyPopulation |\n",
    "        MedicalCondition |\n",
    "        StudyPopulationHasMedicalCondition |\n",
    "        StudyPopulationInTreatmentArm\n",
    "        ]\n",
    "        A list of entities and relationships extracted from the text chunk.\n",
    "        If the response is truncated, an empty list is returned.\n",
    "        If retries are exhausted, an empty list is returned.\n",
    "        If the response is invalid, an empty list is returned.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = await client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt.format(text_chunk=text_chunk)}\n",
    "            ],\n",
    "            response_model=list[\n",
    "                            Medication | \n",
    "                            TreatmentArm | \n",
    "                            ClinicalOutcome | \n",
    "                            MedicationUsedInTreatmentArm | \n",
    "                            TreatmentArmHasClinicalOutcome |\n",
    "                            StudyPopulation |\n",
    "                            MedicalCondition |\n",
    "                            StudyPopulationHasMedicalCondition |\n",
    "                            StudyPopulationInTreatmentArm\n",
    "                            ],\n",
    "            temperature=0.0\n",
    "        )\n",
    "        return response\n",
    "    except IncompleteOutputException as e:\n",
    "        # Handle truncated output\n",
    "        print(f\"Response output truncated. Skipping chunk {chunk_id}.\")\n",
    "        return list()\n",
    "    except InstructorRetryException as e:\n",
    "        # Handle retry exhaustion\n",
    "        print(f\"Failed after {e.n_attempts} attempts. Skipping chunk {chunk_id}.\")\n",
    "        return list()\n",
    "    except ValidationError as e:\n",
    "        # Handle validation errors\n",
    "        print(f\"Validation failed. Skipping chunk {chunk_id}.\\nError: {e}\")\n",
    "        return list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def extract_entities_from_chunk_nodes(chunk_nodes_dataframe: pd.DataFrame, batch_size: int = 100) -> list[tuple[str, list[Any]]]:\n",
    "    \"\"\"\n",
    "    Process a Pandas DataFrame of Chunk nodes and return the entities found in each chunk.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    chunk_nodes_dataframe : pd.DataFrame\n",
    "        A Pandas DataFrame where each row represents a Chunk node.\n",
    "        Has columns `id` and `text`.\n",
    "    batch_size : int\n",
    "        The number of text chunks to process in each batch.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[tuple[str, list[dict[str, Any]]]]\n",
    "        A list of tuples, where the first element is the chunk id and the second element is a list of entities found in the chunk.\n",
    "    \"\"\"\n",
    "\n",
    "    results = list()\n",
    "\n",
    "    for batch_idx, i in enumerate(range(0, len(chunk_nodes_dataframe), batch_size)):\n",
    "        if i + batch_size >= len(chunk_nodes_dataframe):\n",
    "            batch = chunk_nodes_dataframe.iloc[i:]\n",
    "        else:\n",
    "            batch = chunk_nodes_dataframe.iloc[i:i+batch_size]\n",
    "        print(f\"Processing batch {batch_idx+1} of {int(len(chunk_nodes_dataframe)/(batch_size))}  \\n\", end=\"\\r\")\n",
    "        # TODO: implement cache of failed chunks\n",
    "        \n",
    "        # Create tasks for all nodes in the batch\n",
    "        # order is maintained\n",
    "        tasks = [extract_entities_from_text_chunk(row[\"text\"], row['id']) for _, row in batch.iterrows()]\n",
    "        # Execute all tasks concurrently\n",
    "        extraction_results = await asyncio.gather(*tasks)\n",
    "        # Add extracted records to the results list\n",
    "        results.extend(extraction_results)\n",
    "\n",
    "    # Return chunk_id paired with its entities from the results list\n",
    "    return [(chunk_id, entities) for chunk_id, entities in zip(chunk_nodes_dataframe[\"id\"], results)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now defined \n",
    "* Domain data model\n",
    "* Entity extraction logic for chunks\n",
    "\n",
    "It is now time to define our ingestion logic. We will run ingest in two stages \n",
    "\n",
    "1. Extract Domain / Entity Graph from lexical graph Chunk nodes\n",
    "2. Ingest entities into Domain Graph\n",
    "\n",
    "Decoupling these stages allows us easily make changes as we iterate our ingestion process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from pyneoinstance import Neo4jInstance, load_yaml_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our database credentials and all of our queries are stored in the `pyneoinstance_config.yaml` file. \n",
    "\n",
    "This makes it easy to manage our queries and keeps the notebook code clean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_yaml_file(\"pyneoinstance_config.yaml\")\n",
    "\n",
    "db_info = config['db_info']\n",
    "\n",
    "constraints = config['initializing_queries']['constraints']\n",
    "indexes = config['initializing_queries']['indexes']\n",
    "\n",
    "node_load_queries = config['loading_queries']['nodes']\n",
    "relationship_load_queries = config['loading_queries']['relationships']\n",
    "\n",
    "processing_queries = config['processing_queries']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph object will handle database connections and read / write transactions for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Neo4jInstance(db_info.get('uri', os.getenv(\"NEO4J_URI\", \"neo4j://localhost:7687\")), # use config value -> use env value -> use default value\n",
    "                      db_info.get('user', os.getenv(\"NEO4J_USER\", \"neo4j\")), \n",
    "                      db_info.get('password', os.getenv(\"NEO4J_PASSWORD\", \"password\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a helper function for ingesting data using the PyNeoInstance library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_partition(data: pd.DataFrame, batch_size: int = 500) -> int:\n",
    "    \"\"\"\n",
    "    Determine the data partition based on the desired batch size.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : pd.DataFrame\n",
    "        The Pandas DataFrame to partition.\n",
    "    batch_size : int\n",
    "        The desired batch size.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        The partition size.\n",
    "    \"\"\"\n",
    "    \n",
    "    partition = int(len(data) / batch_size)\n",
    "    print(\"partition: \"+str(partition if partition > 1 else 1))\n",
    "    return partition if partition > 1 else 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we write all the constraints and indexes we need for both the lexical and domain graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_constraints_and_indexes() -> None:\n",
    "    \"\"\"\n",
    "    Create constraints and indexes for the lexical and domain graphs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if constraints and len(constraints) > 0:\n",
    "            graph.execute_write_queries(database=db_info['database'], queries=list(constraints.values()))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    try:\n",
    "        if indexes and len(indexes) > 0:\n",
    "            graph.execute_write_queries(database=db_info['database'], queries=list(indexes.values()))\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_constraints_and_indexes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Entities from Lexical Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now perform entity extraction on the Chunk nodes to augment and connect to our patient journey graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunk_nodes_to_process(min_length: int = 100) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Retrieve Chunk node id and text from the database that don't have an embedding.\n",
    "    These chunks may then be used as input to the entity extraction process.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    min_length : int\n",
    "        The minimum length the text must be to be included in the DataFrame.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A Pandas DataFrame where each row represents a Chunk node that has text and is at least `min_length` characters long.\n",
    "        Has columns `id` and `text`.\n",
    "    \"\"\"\n",
    "    return graph.execute_read_query(database=db_info['database'], \n",
    "                            query=processing_queries['get_chunk_nodes_to_process'], \n",
    "                            parameters={\"min_length\": min_length},\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.UnknownPropertyKeyWarning} {category: UNRECOGNIZED} {title: The provided property key is not in the database} {description: One of the property names in your query is not available in the database, make sure you didn't misspell it or that the label is available when you run this statement in your application (the missing property name is: embedding)} {position: line: 3, column: 9, offset: 49} for query: 'MATCH (c:Chunk)\\nWHERE c.text IS NOT NULL\\n  AND c.embedding IS NULL\\n  AND size(c.text) >= $min_length\\nRETURN c.id as id, c.text as text\\n'\n"
     ]
    }
   ],
   "source": [
    "chunks_to_process = get_chunk_nodes_to_process(min_length=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 494 chunks to process\n",
      "\n",
      "First chunk:\n",
      "\n",
      "statistical significance (metformin + Ex9-39 vs. placebo + Ex9-39, P = 0.053). The glucose iAUC after metformin + saline was significantly smaller than the iAUC for metformin + Ex9-39 (P = 0.004). Based on individual iAUC values, the relative contribution of GLP-1 to the acute glucose-lowering effect of metformin was 75% ± 35%, calculated as follows: 100% × ([iAUCplacebo + saline – iAUCmetformin + saline] – [iAUCplacebo + Ex9–39 – iAUCmetformin + Ex9–39])/(iAUCplacebo + saline – iAUCmetformin + saline) (P = 0.05). Using a 2-way ANOVA, both metformin and Ex9-39 were shown to significantly affect postprandial plasma glucose (iAUC) (P = 0.005 and P = 0.002, respectively), but no interaction between the 2 factors was evident. The time courses of the C-peptide/glucose ratios are illustrated in Figure 2B, and the AUCs for C-peptide/glucose, insulin/glucose, and insulin secretion\n"
     ]
    }
   ],
   "source": [
    "print(f\"Found {len(chunks_to_process)} chunks to process\\n\")\n",
    "print(f\"First chunk:\\n\\n{chunks_to_process.loc[0,'text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1 of 10  \n",
      "Failed after 3 attempts. Skipping chunk.\n",
      "Processing batch 2 of 10  \n",
      "Processing batch 3 of 10  \n",
      "Processing batch 4 of 10  \n",
      "Failed after 3 attempts. Skipping chunk.\n",
      "Processing batch 5 of 10  \n",
      "Processing batch 6 of 10  \n",
      "Processing batch 7 of 10  \n",
      "Processing batch 8 of 10  \n",
      "Processing batch 9 of 10  \n",
      "Processing batch 10 of 10  \n",
      "\r"
     ]
    }
   ],
   "source": [
    "extracted_entities_with_chunk_ids = await extract_entities_from_chunk_nodes(chunks_to_process[:200], batch_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingest Entities Into Knowledge Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions load the extracted entities and relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions link the extracted entities with their text chunk nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENTITY_LABELS = {\n",
    "    \"Medication\", \n",
    "    \"TreatmentArm\",\n",
    "    \"MedicalCondition\",\n",
    "    \"StudyPopulation\",\n",
    "    \"ClinicalOutcome\",\n",
    "}\n",
    "\n",
    "ENTITY_RELS = {\n",
    "    \"MedicationUsedInTreatmentArm\",\n",
    "    \"TreatmentArmHasClinicalOutcome\",\n",
    "    \"StudyPopulationInTreatmentArm\",\n",
    "    \"StudyPopulationHasMedicalCondition\",\n",
    "}\n",
    "\n",
    "def prepare_entities_for_ingestion(entities: list[tuple[str, list[Any]]]) -> dict[str, dict[str, pd.DataFrame]]:\n",
    "    \"\"\"\n",
    "    Prepare entities for ingestion into the graph.\n",
    "    This function takes the results of the `get_chunk_nodes_to_process_by_article_name` function and returns a dictionary of entity label keys and Pandas DataFrames of entities.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    entities : list[tuple[str, list[Any]]]\n",
    "        A list of tuples, where the first element is the chunk id and the second element is a list of entities found in the chunk.\n",
    "        Entities are Pydantic models that adhere to the domain graph data model.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict[str, dict[str, pd.DataFrame]]\n",
    "        A dictionary of entity label to pandas dataframe of entities.\n",
    "\n",
    "        {\n",
    "            \"nodes\": {\n",
    "                \"Medication\": pd.DataFrame(...),\n",
    "                \"StudyMedication\": pd.DataFrame(...),\n",
    "                ...\n",
    "            },\n",
    "            \"relationships\": {\n",
    "                \"StudyMedicationUsesMedication\": pd.DataFrame(...),\n",
    "                \"StudyMedicationProducesClinicalOutcome\": pd.DataFrame(...),\n",
    "                ...\n",
    "            }\n",
    "        }\n",
    "    \"\"\"\n",
    "\n",
    "    records_node_dict = {lbl: list() for lbl in ENTITY_LABELS}\n",
    "    records_rel_dict = {lbl: list() for lbl in ENTITY_RELS}\n",
    "\n",
    "    for chunk_id, entities in entities:\n",
    "        for entity in entities:\n",
    "            to_add = entity.model_dump()\n",
    "            to_add.update({\"chunk_id\": chunk_id})\n",
    "            # nodes\n",
    "            if entity.__class__.__name__ in ENTITY_LABELS:\n",
    "                records_node_dict[entity.__class__.__name__].append(to_add)\n",
    "            # rels\n",
    "            elif entity.__class__.__name__ in ENTITY_RELS:\n",
    "                records_rel_dict[entity.__class__.__name__].append(to_add)\n",
    "            else:\n",
    "                print(f\"Unknown entity type: {entity.__class__.__name__}\")\n",
    "\n",
    "    for key, value in records_node_dict.items():\n",
    "        records_node_dict[key] = pd.DataFrame(value).replace({float('nan'): None})\n",
    "\n",
    "    for key, value in records_rel_dict.items():\n",
    "        records_rel_dict[key] = pd.DataFrame(value).replace({float('nan'): None})\n",
    "\n",
    "    return {\"nodes\": records_node_dict, \"relationships\": records_rel_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_entity_nodes(medication_dataframe: pd.DataFrame, \n",
    "                      medical_condition_dataframe: pd.DataFrame, \n",
    "                      treatment_arm_dataframe: pd.DataFrame, \n",
    "                      study_population_dataframe: pd.DataFrame, \n",
    "                      clinical_outcome_dataframe: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Load entity nodes into the graph.\n",
    "    \"\"\"\n",
    "    \n",
    "    entity_nodes_ingest_iterator = list(zip([medication_dataframe, \n",
    "                                             medical_condition_dataframe, \n",
    "                                             treatment_arm_dataframe, \n",
    "                                             study_population_dataframe, \n",
    "                                             clinical_outcome_dataframe], \n",
    "                                             ['medication', \n",
    "                                              'medical_condition', \n",
    "                                              'treatment_arm', \n",
    "                                              'study_population', \n",
    "                                              'clinical_outcome']))\n",
    "\n",
    "    for data, query in entity_nodes_ingest_iterator:\n",
    "        if len(data) > 0:\n",
    "            print(f\"Loading {len(data)} {query} nodes\")\n",
    "            res = graph.execute_write_query_with_data(database=db_info['database'], \n",
    "                                                    data=data, \n",
    "                                                    query=node_load_queries[query], \n",
    "                                                    partitions=get_partition(data, batch_size=500),\n",
    "                                                    parallel=False)\n",
    "            print(res)\n",
    "        else:\n",
    "            print(f\"No {query} nodes to load\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_entity_relationships(medication_used_in_treatment_arm_dataframe: pd.DataFrame,\n",
    "                              treatment_arm_has_clinical_outcome_dataframe: pd.DataFrame,\n",
    "                              study_population_in_treatment_arm_dataframe: pd.DataFrame,\n",
    "                              study_population_has_medical_condition_dataframe: pd.DataFrame,\n",
    "                              ) -> None:\n",
    "    \"\"\"\n",
    "    Load entity relationships into the graph.\n",
    "    \"\"\"\n",
    "    entity_relationships_ingest_iterator = list(zip([medication_used_in_treatment_arm_dataframe, \n",
    "                                                      treatment_arm_has_clinical_outcome_dataframe, \n",
    "                                                      study_population_in_treatment_arm_dataframe, \n",
    "                                                      study_population_has_medical_condition_dataframe, \n",
    "                                                      ], \n",
    "                                                      ['medication_used_in_treatment_arm', \n",
    "                                                       'treatment_arm_has_clinical_outcome', \n",
    "                                                       'study_population_in_treatment_arm', \n",
    "                                                       'study_population_has_medical_condition', \n",
    "                                                       ]))\n",
    "    \n",
    "    for data, query in entity_relationships_ingest_iterator:\n",
    "        if len(data) > 0:\n",
    "            print(f\"Loading {len(data)} {query} relationships\")\n",
    "            res = graph.execute_write_query_with_data(database=db_info['database'], \n",
    "                                                    data=data, \n",
    "                                                    query=relationship_load_queries[query], \n",
    "                                                    partitions=get_partition(data, batch_size=500),\n",
    "                                                    parallel=False)\n",
    "            print(res)\n",
    "        else:\n",
    "            print(f\"No {query} relationships to load\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_entities_to_chunks(medication_link_dataframe: pd.DataFrame, \n",
    "                      medical_condition_link_dataframe: pd.DataFrame, \n",
    "                      treatment_arm_link_dataframe: pd.DataFrame, \n",
    "                      study_population_link_dataframe: pd.DataFrame, \n",
    "                      clinical_outcome_link_dataframe: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Link entities to chunks.\n",
    "    \"\"\"\n",
    "    entity_link_iterator = list(zip([medication_link_dataframe, \n",
    "                                     medical_condition_link_dataframe, \n",
    "                                     treatment_arm_link_dataframe, \n",
    "                                     study_population_link_dataframe, \n",
    "                                     clinical_outcome_link_dataframe], \n",
    "                                     [\"chunk_has_entity_medication\",\n",
    "                                      \"chunk_has_entity_medical_condition\",\n",
    "                                      \"chunk_has_entity_treatment_arm\",\n",
    "                                      \"chunk_has_entity_study_population\",\n",
    "                                      \"chunk_has_entity_clinical_outcome\"]))\n",
    "    \n",
    "    for data, query in entity_link_iterator:\n",
    "        if len(data) > 0:\n",
    "            print(f\"Linking {len(data)} {query} entities to chunks\")\n",
    "            res = graph.execute_write_query_with_data(database=db_info['database'], \n",
    "                                                    data=data, \n",
    "                                                    query=relationship_load_queries[query], \n",
    "                                                    partitions=get_partition(data, batch_size=500),\n",
    "                                                    parallel=False)\n",
    "            print(res)\n",
    "        else:\n",
    "            print(f\"No {query} relationships to load\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingest_records = prepare_entities_for_ingestion(extracted_entities_with_chunk_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 271 medication nodes\n",
      "partition: 1\n",
      "{'properties_set': 1355}\n",
      "Loading 66 medical_condition nodes\n",
      "partition: 1\n",
      "{'labels_added': 32, 'nodes_created': 32, 'properties_set': 296}\n",
      "Loading 232 treatment_arm nodes\n",
      "partition: 1\n",
      "{'labels_added': 211, 'nodes_created': 211, 'properties_set': 675}\n",
      "Loading 84 study_population nodes\n",
      "partition: 1\n",
      "{'labels_added': 75, 'nodes_created': 75, 'properties_set': 1167}\n",
      "No clinical_outcome nodes to load\n"
     ]
    }
   ],
   "source": [
    "load_entity_nodes(ingest_records[\"nodes\"][\"Medication\"], \n",
    "                  ingest_records[\"nodes\"][\"MedicalCondition\"], \n",
    "                  ingest_records[\"nodes\"][\"TreatmentArm\"], \n",
    "                  ingest_records[\"nodes\"][\"StudyPopulation\"], \n",
    "                  ingest_records[\"nodes\"][\"ClinicalOutcome\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_name</th>\n",
       "      <th>treatment_arm_name</th>\n",
       "      <th>clinical_outcome_name</th>\n",
       "      <th>clinical_outcome_id</th>\n",
       "      <th>treatment_arm_id</th>\n",
       "      <th>chunk_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Exenatide Once Weekly vs. Sitagliptin Study</td>\n",
       "      <td>Exenatide Once Weekly Arm</td>\n",
       "      <td>A1C Reduction</td>\n",
       "      <td>d30cc00f1297fdb298bb9cc23cf88667959d6e4c603da5...</td>\n",
       "      <td>69685cf6a8d172ad3a798c63a0b7012d96108bc1e09a8a...</td>\n",
       "      <td>072f6fc5f143b89bf521a5b75867f080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Exenatide Once Weekly vs. Sitagliptin Study</td>\n",
       "      <td>Exenatide Once Weekly Arm</td>\n",
       "      <td>Weight Loss</td>\n",
       "      <td>e58e46dddf01a2ccfa430c114b5334b0142c067024af4d...</td>\n",
       "      <td>69685cf6a8d172ad3a798c63a0b7012d96108bc1e09a8a...</td>\n",
       "      <td>072f6fc5f143b89bf521a5b75867f080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Exenatide Once Weekly vs. Sitagliptin Study</td>\n",
       "      <td>Sitagliptin Arm</td>\n",
       "      <td>A1C Reduction</td>\n",
       "      <td>d30cc00f1297fdb298bb9cc23cf88667959d6e4c603da5...</td>\n",
       "      <td>fac4659b2549c2320f07dfd4cb459332a11db9e7b82cbe...</td>\n",
       "      <td>072f6fc5f143b89bf521a5b75867f080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Exenatide Once Weekly vs. Sitagliptin Study</td>\n",
       "      <td>Sitagliptin Arm</td>\n",
       "      <td>Weight Loss</td>\n",
       "      <td>e58e46dddf01a2ccfa430c114b5334b0142c067024af4d...</td>\n",
       "      <td>fac4659b2549c2320f07dfd4cb459332a11db9e7b82cbe...</td>\n",
       "      <td>072f6fc5f143b89bf521a5b75867f080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Network Meta-Analysis of Exenatide</td>\n",
       "      <td>Exenatide Arm</td>\n",
       "      <td>Glycemic control improvement</td>\n",
       "      <td>11b3ba7c3a0f9f07966bf715a1a4636df87c4e0eae85fa...</td>\n",
       "      <td>a055949ab18ff5de56a6221bd9cbf4d29ae8ec6fdc6d71...</td>\n",
       "      <td>0ae41eb129a57859103e320c0cafe3d7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Ahren et al. (48)</td>\n",
       "      <td>Placebo</td>\n",
       "      <td>Change in HbA1c for Placebo</td>\n",
       "      <td>64f0e6ca962a82b233e2752c307114b749abb4623daf54...</td>\n",
       "      <td>ffc331a0ef346b0180835f8330294ab826904e0827b7b1...</td>\n",
       "      <td>62c8f7607d7c903b4179eaba82922516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>Ahren et al. (48)</td>\n",
       "      <td>Albiglutide 30mg</td>\n",
       "      <td>Weight change for Albiglutide</td>\n",
       "      <td>e2e6a80ffb14582bba41184fa8baece63cee7cfe058772...</td>\n",
       "      <td>31fd566f895b4ef5ae947546b1d90e77aa2db0db3675f9...</td>\n",
       "      <td>62c8f7607d7c903b4179eaba82922516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Ahren et al. (48)</td>\n",
       "      <td>Sitagliptin 100mg</td>\n",
       "      <td>Weight change for Sitagliptin</td>\n",
       "      <td>07fb2b384d0e8e90c31aec165967ece04ebd445e9fdf03...</td>\n",
       "      <td>aeca001e5e7406c604998f575cb11ae64d5db4ba1693e3...</td>\n",
       "      <td>62c8f7607d7c903b4179eaba82922516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Ahren et al. (48)</td>\n",
       "      <td>Glimepiride 2mg</td>\n",
       "      <td>Weight change for Glimepiride</td>\n",
       "      <td>f1f7103127a3d2573c6a07763fd1a832b7cfb68fa4a5b5...</td>\n",
       "      <td>9bdcba3126d14f3bcdd63988e4430a7bab92e010039e8e...</td>\n",
       "      <td>62c8f7607d7c903b4179eaba82922516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Ahren et al. (48)</td>\n",
       "      <td>Placebo</td>\n",
       "      <td>Weight change for Placebo</td>\n",
       "      <td>8558586ceddbe420cbf24e6b9b197d38af4e90f747a3e2...</td>\n",
       "      <td>ffc331a0ef346b0180835f8330294ab826904e0827b7b1...</td>\n",
       "      <td>62c8f7607d7c903b4179eaba82922516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      study_name         treatment_arm_name  \\\n",
       "0    Exenatide Once Weekly vs. Sitagliptin Study  Exenatide Once Weekly Arm   \n",
       "1    Exenatide Once Weekly vs. Sitagliptin Study  Exenatide Once Weekly Arm   \n",
       "2    Exenatide Once Weekly vs. Sitagliptin Study            Sitagliptin Arm   \n",
       "3    Exenatide Once Weekly vs. Sitagliptin Study            Sitagliptin Arm   \n",
       "4             Network Meta-Analysis of Exenatide              Exenatide Arm   \n",
       "..                                           ...                        ...   \n",
       "114                            Ahren et al. (48)                    Placebo   \n",
       "115                            Ahren et al. (48)           Albiglutide 30mg   \n",
       "116                            Ahren et al. (48)          Sitagliptin 100mg   \n",
       "117                            Ahren et al. (48)            Glimepiride 2mg   \n",
       "118                            Ahren et al. (48)                    Placebo   \n",
       "\n",
       "             clinical_outcome_name  \\\n",
       "0                    A1C Reduction   \n",
       "1                      Weight Loss   \n",
       "2                    A1C Reduction   \n",
       "3                      Weight Loss   \n",
       "4     Glycemic control improvement   \n",
       "..                             ...   \n",
       "114    Change in HbA1c for Placebo   \n",
       "115  Weight change for Albiglutide   \n",
       "116  Weight change for Sitagliptin   \n",
       "117  Weight change for Glimepiride   \n",
       "118      Weight change for Placebo   \n",
       "\n",
       "                                   clinical_outcome_id  \\\n",
       "0    d30cc00f1297fdb298bb9cc23cf88667959d6e4c603da5...   \n",
       "1    e58e46dddf01a2ccfa430c114b5334b0142c067024af4d...   \n",
       "2    d30cc00f1297fdb298bb9cc23cf88667959d6e4c603da5...   \n",
       "3    e58e46dddf01a2ccfa430c114b5334b0142c067024af4d...   \n",
       "4    11b3ba7c3a0f9f07966bf715a1a4636df87c4e0eae85fa...   \n",
       "..                                                 ...   \n",
       "114  64f0e6ca962a82b233e2752c307114b749abb4623daf54...   \n",
       "115  e2e6a80ffb14582bba41184fa8baece63cee7cfe058772...   \n",
       "116  07fb2b384d0e8e90c31aec165967ece04ebd445e9fdf03...   \n",
       "117  f1f7103127a3d2573c6a07763fd1a832b7cfb68fa4a5b5...   \n",
       "118  8558586ceddbe420cbf24e6b9b197d38af4e90f747a3e2...   \n",
       "\n",
       "                                      treatment_arm_id  \\\n",
       "0    69685cf6a8d172ad3a798c63a0b7012d96108bc1e09a8a...   \n",
       "1    69685cf6a8d172ad3a798c63a0b7012d96108bc1e09a8a...   \n",
       "2    fac4659b2549c2320f07dfd4cb459332a11db9e7b82cbe...   \n",
       "3    fac4659b2549c2320f07dfd4cb459332a11db9e7b82cbe...   \n",
       "4    a055949ab18ff5de56a6221bd9cbf4d29ae8ec6fdc6d71...   \n",
       "..                                                 ...   \n",
       "114  ffc331a0ef346b0180835f8330294ab826904e0827b7b1...   \n",
       "115  31fd566f895b4ef5ae947546b1d90e77aa2db0db3675f9...   \n",
       "116  aeca001e5e7406c604998f575cb11ae64d5db4ba1693e3...   \n",
       "117  9bdcba3126d14f3bcdd63988e4430a7bab92e010039e8e...   \n",
       "118  ffc331a0ef346b0180835f8330294ab826904e0827b7b1...   \n",
       "\n",
       "                             chunk_id  \n",
       "0    072f6fc5f143b89bf521a5b75867f080  \n",
       "1    072f6fc5f143b89bf521a5b75867f080  \n",
       "2    072f6fc5f143b89bf521a5b75867f080  \n",
       "3    072f6fc5f143b89bf521a5b75867f080  \n",
       "4    0ae41eb129a57859103e320c0cafe3d7  \n",
       "..                                ...  \n",
       "114  62c8f7607d7c903b4179eaba82922516  \n",
       "115  62c8f7607d7c903b4179eaba82922516  \n",
       "116  62c8f7607d7c903b4179eaba82922516  \n",
       "117  62c8f7607d7c903b4179eaba82922516  \n",
       "118  62c8f7607d7c903b4179eaba82922516  \n",
       "\n",
       "[119 rows x 6 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingest_records[\"relationships\"][\"TreatmentArmHasClinicalOutcome\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 71 medication_used_in_treatment_arm relationships\n",
      "partition: 1\n",
      "{'relationships_created': 55, 'properties_set': 550}\n",
      "Loading 119 treatment_arm_has_clinical_outcome relationships\n",
      "partition: 1\n",
      "{}\n",
      "Loading 24 study_population_in_treatment_arm relationships\n",
      "partition: 1\n",
      "{}\n",
      "Loading 31 study_population_has_medical_condition relationships\n",
      "partition: 1\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "load_entity_relationships(ingest_records[\"relationships\"][\"MedicationUsedInTreatmentArm\"], \n",
    "                          ingest_records[\"relationships\"][\"TreatmentArmHasClinicalOutcome\"], \n",
    "                          ingest_records[\"relationships\"][\"StudyPopulationInTreatmentArm\"], \n",
    "                          ingest_records[\"relationships\"][\"StudyPopulationHasMedicalCondition\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link Entities to Lexical Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we link the loaded entities to their respective Chunk nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linking 271 chunk_has_entity_medication entities to chunks\n",
      "partition: 1\n",
      "{'relationships_created': 271}\n",
      "Linking 66 chunk_has_entity_medical_condition entities to chunks\n",
      "partition: 1\n",
      "{'relationships_created': 66}\n",
      "Linking 232 chunk_has_entity_treatment_arm entities to chunks\n",
      "partition: 1\n",
      "{'relationships_created': 232}\n",
      "Linking 84 chunk_has_entity_study_population entities to chunks\n",
      "partition: 1\n",
      "{'relationships_created': 80}\n",
      "No chunk_has_entity_clinical_outcome relationships to load\n"
     ]
    }
   ],
   "source": [
    "link_entities_to_chunks(ingest_records[\"nodes\"][\"Medication\"], \n",
    "                        ingest_records[\"nodes\"][\"MedicalCondition\"], \n",
    "                        ingest_records[\"nodes\"][\"TreatmentArm\"], \n",
    "                        ingest_records[\"nodes\"][\"StudyPopulation\"], \n",
    "                        ingest_records[\"nodes\"][\"ClinicalOutcome\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link Entity Graph to the Rest of Domain Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we execute custom Cypher to link the extracted entities with the existing patient journey graph.\n",
    "\n",
    "This will create the following relationships\n",
    "\n",
    "* (:Demographic)-[:IN_STUDY_POPULATION]->(:StudyPopulation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other links already exist since we are extracting Medication and MedicalCondtion nodes from the text and these entities already exist in the patient journey graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_domain_and_patient_journey_graph() -> None:\n",
    "    \"\"\"\n",
    "    Link the domain graph with the patient journey graph. \n",
    "    This process doesn't require any input DataFrames. \n",
    "    Instead it attempts to link nodes based on matching properties.\n",
    "    \"\"\"\n",
    "\n",
    "    queries = [\"demographic_in_study_population\"]\n",
    "\n",
    "    for q in queries:\n",
    "        res = graph.execute_write_query(database=db_info['database'], \n",
    "                                        query=relationship_load_queries[q])\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'relationships_created': 150, 'properties_set': 150}\n"
     ]
    }
   ],
   "source": [
    "link_domain_and_patient_journey_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resolve Entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now can perform some entity resolution. \n",
    "\n",
    "The entity extraction process may find entities that are slight variations of existing entities.\n",
    "\n",
    "We can merge these entities together with some Cypher.\n",
    "\n",
    "The following entitites will be resolved:\n",
    "* Medication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_entities() -> None:\n",
    "    \"\"\"\n",
    "    Resolve extracted entities.\n",
    "    This process doesn't require any input DataFrames.\n",
    "    \"\"\"\n",
    "\n",
    "    queries = [\"resolve_medications\"]\n",
    "\n",
    "    for q in queries:\n",
    "        res = graph.execute_write_query(database=db_info['database'], \n",
    "                                        query=processing_queries[q])\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "resolve_entities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
